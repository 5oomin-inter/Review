import streamlit as st
import os
import io
import tempfile
import time
import json
import re
import zipfile
from google import genai
from google.genai import types
from pdf2image import convert_from_path

# ==========================================
# [ì´ˆê¸° ì„¤ì •]
# ==========================================
st.set_page_config(page_title="ì—…ë¬´ ìë™í™”", layout="wide")

# ==========================================
# [ìƒìˆ˜ ë° í™˜ê²½ ì„¤ì •]
# ==========================================
DEFAULT_API_KEY = ""

if os.name == 'nt':
    POPPLER_PATH = r"C:\Users\inter\Desktop\Review\poppler-25.12.0\Library\bin"
else:
    POPPLER_PATH = None

# ==========================================
# [í”„ë¡¬í”„íŠ¸ A] LaTeX ZIPìš© (v8.1 - Table í˜•ì‹)
# ==========================================
PROMPT_FOR_TEX = """
# ğŸ† ì¢…í•© í•™ìˆ  ê°ì‚¬ê´€ (Scholarly Auditor v8.1)

## 1. ğŸ¥‡ í•µì‹¬ ì •ì²´ì„±
ê·€í•˜ëŠ” ê³ ë“± ìˆ˜í•™ êµìœ¡ ì½˜í…ì¸ ì˜ **ìµœì¢… ê²€ì¦ì**ì´ì **ê¸°ìˆ ì  í¸ì§‘ì**ì…ë‹ˆë‹¤.

## 2. ğŸ“ ì¶œë ¥ í‘œì¤€ (Output format) - ì¤‘ìš”!
**ë°˜ë“œì‹œ ì•„ë˜ì˜ í‘œ(Table) í˜•ì‹ì„ ì—„ìˆ˜í•˜ì‹­ì‹œì˜¤.**

### 1. ğŸ“ [Table A: í•™ìˆ  ê°ì‚¬ ë³´ê³ ì„œ] (ì¹˜ëª…ì  ì˜¤ë¥˜)
* **ê¸°ì¤€:** ìˆ˜í•™ì  ì§„ë¦¬ê°’ ì˜¤ë¥˜, ì •ë‹µ ì˜¤ë¥˜, ì¹˜ëª…ì  ì˜¤ê°œë… (í™•ì‹ ë„ 100%)
* **ì–‘ì‹:**
| ìœ„ì¹˜ | ì˜¤ë¥˜ ë‚´ìš© | ì›ë¬¸ $\\to$ ìˆ˜ì • ì œì•ˆ | ê·¼ê±° ë° ì˜ê²¬ |
| :--- | :--- | :--- | :--- |
| (ì˜ˆ: í•´ì„¤ 3í–‰) | (ì˜ˆ: ë¶€í˜¸ ì˜¤ë¥˜) | **[ì›ë¬¸]** $f(t)$ <br> $\\downarrow$ <br> **[ìˆ˜ì •]** $f(-t)$ | (ì˜ˆ: yì¶• ëŒ€ì¹­ì´ë¯€ë¡œ -t ëŒ€ì… í•„ìš”) |

### 2. ğŸ§¹ [Table B: ë³€í™˜ ì˜¤ë¥˜ í´ë¦°ì—…] (ë‹¨ìˆœ ìˆ˜ì •)
* **ê¸°ì¤€:** ë„ì–´ì“°ê¸°, ì˜¤íƒ€, LaTeX ë¬¸ë²•, ë‹¨ìˆœ í¸ì§‘
* **ì–‘ì‹:**
| ìœ„ì¹˜ | ì˜¤ë¥˜ ë‚´ìš© | ì›ë¬¸ $\\to$ ìˆ˜ì • ì œì•ˆ |
| :--- | :--- | :--- |
| (ì˜ˆ: ë¬¸ì œ 1í–‰) | (ì˜ˆ: ë„ì–´ì“°ê¸°) | 3 ê°œë¥¼ $\\to$ 3ê°œë¥¼ |

### 3. ğŸ’¡ [Table C: ê°œì„  ì œì•ˆ] (ê¶Œì¥ ì‚¬í•­)
* **ê¸°ì¤€:** ë” ë‚˜ì€ í’€ì´, ê°€ë…ì„±, êµìœ¡ì  ì œì•ˆ
* **ì–‘ì‹:**
| ìœ„ì¹˜ | ì œì•ˆ ìœ í˜• | ë‚´ìš© ë° ì˜ê²¬ |
| :--- | :--- | :--- |
| (ì˜ˆ: ì‹ (ë‚˜)) | (ì˜ˆ: í’€ì´ ê°œì„ ) | í˜„ì¬ í’€ì´ë³´ë‹¤ ë¡œí”¼íƒˆ ì •ë¦¬ë¥¼ ì´ìš©í•˜ëŠ” ê²ƒì´ ë” ì§ê´€ì ì…ë‹ˆë‹¤. |

## 3. ğŸš« ì¶œë ¥ ì œì–´ ê·œì¹™
1. **Perfect Score:** ìˆ˜ì • ì‚¬í•­ì´ ì—†ìœ¼ë©´ "âœ… [ë¬´ê²°ì  ì¸ì¦]"ë§Œ ì¶œë ¥.
2. **Table Integrity:** ë‚´ìš©ì´ ìˆëŠ” í‘œë§Œ ì¶œë ¥í•˜ê³ , ë¹ˆ í‘œëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

## 4. ğŸ“Š <FINAL REPORT>
(ìœ„ ì–‘ì‹ì— ë§ì¶° ì¶œë ¥)
<FINAL REPORT>
... (AI Report Content) ...
</FINAL REPORT>
"""

# ==========================================
# [í”„ë¡¬í”„íŠ¸ B] 2512 PDFìš© (Legacy - JSON í˜•ì‹)
# ==========================================
PROMPT_FOR_PDF = """
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ê³ ë“±í•™êµ ìˆ˜í•™ êµì¬ ì „ë¬¸ êµì •ìì…ë‹ˆë‹¤.
ì•„ë˜ í…ìŠ¤íŠ¸ì—ì„œ ì˜¤ë¥˜ë¥¼ ì°¾ì•„ ë³´ê³ í•´ì£¼ì„¸ìš”.

[ê²€í†  ê¸°ì¤€]
1. ì¡°ì‚¬ ì—°ê²°: ìˆ˜ì‹ ë’¤ì˜ ì¡°ì‚¬($f(x)$ëŠ”/ì€ ë“±)ê°€ ìì—°ìŠ¤ëŸ¬ìš´ì§€
2. ë§ì¶¤ë²•/ë„ì–´ì“°ê¸°: ê¸°ë³¸ì ì¸ í•œêµ­ì–´ ë§ì¶¤ë²• ì¤€ìˆ˜
3. í”¼ë™/ì‚¬ë™: 'ë˜ì–´ì§€ë‹¤', 'ë³´ì—¬ì§€ë‹¤' ë“± ì´ì¤‘ í”¼ë™ ì§€ì–‘
4. ëŒ€ë“± ì—°ê²°: ë¬¸ì¥ ë‚˜ì—´ ì‹œ êµ¬ì¡°ì  ëŒ€ë“±ì„± ìœ ì§€
5. ì£¼ìˆ  í˜¸ì‘: ì£¼ì–´ì™€ ì„œìˆ ì–´ì˜ ê´€ê³„ê°€ ëª…í™•í•œì§€
6. ì¤‘ì˜ì„±: í•´ì„ì´ ëª¨í˜¸í•œ ë¬¸ì¥ ìˆ˜ì •
7. ìˆ˜í•™ ìš©ì–´: ê³ êµ ê³¼ì •ì— ë§ëŠ” ì •í™•í•œ ìš©ì–´ ì‚¬ìš©
8. ë³€ìˆ˜ ì¼ê´€ì„±: ì •ì˜ëœ ë³€ìˆ˜ê°€ ëê¹Œì§€ ìœ ì§€ë˜ëŠ”ì§€
9. ì˜¤íƒ€: ë‹¨ìˆœ ì˜¤íƒ€ ë° OCR ì˜¤ë¥˜

[ì…ë ¥ í…ìŠ¤íŠ¸]
{section_text}

[ì¶œë ¥ í˜•ì‹]
ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ JSON ë°°ì—´ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ì˜¤ë¥˜ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ []ì„ ì¶œë ¥í•˜ì„¸ìš”.
ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.

[
    {{
        "original": "ë¬¸ì œê°€ ìˆëŠ” ë¶€ë¶„",
        "corrected": "ìˆ˜ì • ì œì•ˆ",
        "reason": "ìˆ˜ì • ì´ìœ  (ê¸°ì¤€ ë²ˆí˜¸ í¬í•¨)",
        "severity": "high/medium/low"
    }}
]
"""

# ==========================================
# [ê³µí†µ ìœ í‹¸ë¦¬í‹°: ì¡°ì‚¬ ê·œì¹™ ê²€ì‚¬ ë“±]
# ==========================================
_JONGSUNG_LIST = ["", "ã„±", "ã„²", "ã„³", "ã„´", "ã„µ", "ã„¶", "ã„·", "ã„¹", "ã„º", "ã„»", "ã„¼", "ã„½", "ã„¾", "ã„¿", "ã…€", "ã…", "ã…‚", "ã…„", "ã……", "ã…†", "ã…‡", "ã…ˆ", "ã…Š", "ã…‹", "ã…Œ", "ã…", "ã…"]
_LATIN_LAST_JONG = {"A": "", "B": "", "C": "", "D": "", "E": "", "F": "", "G": "", "H": "", "I": "", "J": "", "K": "", "L": "ã„¹", "M": "ã…", "N": "ã„´", "O": "", "P": "", "Q": "", "R": "ã„¹", "S": "", "T": "", "U": "", "V": "", "W": "", "X": "", "Y": "", "Z": ""}
_DIGIT_LAST_JONG = {"0": "ã…‡", "1": "ã„¹", "2": "", "3": "ã…", "4": "", "5": "", "6": "ã„±", "7": "ã„¹", "8": "ã„¹", "9": ""}
_JOSA_CANDIDATES = ("ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ê³¼", "ì™€", "ìœ¼ë¡œ", "ë¡œ")
_MATH_JOSA_PATTERN = re.compile(r'(?P<math>\${1,2}[^$]+?\${1,2})(?P<ws>\s*)(?P<josa>ìœ¼ë¡œ|ë¡œ|ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ê³¼|ì™€)(?=[\s\.,;:\)\]\}\!?]|$)')
_NUM_JOSA_PATTERN = re.compile(r'(?P<num>\d[\d,]*(?:\.\d+)?)(?P<ws>\s*)(?P<josa>ìœ¼ë¡œ|ë¡œ|ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ê³¼|ì™€)(?=[\s\.,;:\)\]\}\!?]|$)')

def _hangul_last_jong(text):
    if not text: return ""
    s = re.sub(r'[\s\.,;:!\?\)\]\}]+$', '', text.strip())
    for ch in reversed(s):
        code = ord(ch)
        if 0xAC00 <= code <= 0xD7A3: return _JONGSUNG_LIST[(code - 0xAC00) % 28]
    return ""
def _latin_last_jong(text):
    s = text.strip()
    if not s: return ""
    for ch in reversed(s):
        if ch.isalpha(): return _LATIN_LAST_JONG.get(ch.upper(), "")
    return ""
def _number_last_jong(num_raw):
    if not num_raw: return ""
    s = num_raw.strip().replace(",", "").replace(" ", "").lstrip("+")
    if s.startswith("-"): s = s[1:]
    if "." in s: return _DIGIT_LAST_JONG.get(s.split(".")[1][-1], "") if s.split(".")[1] else ""
    digits = re.sub(r"\D", "", s).lstrip("0") or "0"
    if digits == "0": return "ã…‡"
    return _DIGIT_LAST_JONG.get(digits[-1], "")

def _expected_josa(josa, last_jong):
    has = (last_jong != "")
    if josa in ("ì€", "ëŠ”"): return "ì€" if has else "ëŠ”"
    if josa in ("ì´", "ê°€"): return "ì´" if has else "ê°€"
    if josa in ("ì„", "ë¥¼"): return "ì„" if has else "ë¥¼"
    if josa in ("ê³¼", "ì™€"): return "ê³¼" if has else "ì™€"
    if josa in ("ìœ¼ë¡œ", "ë¡œ"): return "ë¡œ" if (not has or last_jong == "ã„¹") else "ìœ¼ë¡œ"
    return josa

def _strip_math_delimiters(math): return math.strip("$")
def _last_jong_from_math(math): return "" 
def _last_jong_from_text(text): return "" 

def get_line_number(full_text, index):
    return full_text.count('\n', 0, index) + 1

def rule_check_josa(section_text):
    errors = []
    # 1. ìˆ˜ì‹ ë’¤ ì¡°ì‚¬
    for m in _MATH_JOSA_PATTERN.finditer(section_text):
        math = m.group("math")
        ws = m.group("ws") or ""
        josa = m.group("josa")
        last_jong = _last_jong_from_math(math)
        exp = _expected_josa(josa, last_jong)
        original = f"{math}{ws}{josa}"
        corrected = f"{math}{exp}"
        line_num = get_line_number(section_text, m.start())
        if josa != exp or ws:
            errors.append({"location": f"{line_num}í–‰", "original": original, "corrected": corrected, "reason": "ì¡°ì‚¬ ì˜¤ë¥˜(ìˆ˜ì‹)", "severity": "medium"})
    # 2. ìˆ«ì ë’¤ ì¡°ì‚¬
    for m in _NUM_JOSA_PATTERN.finditer(section_text):
        num = m.group("num")
        ws = m.group("ws") or ""
        josa = m.group("josa")
        if m.start() > 0 and section_text[m.start() - 1] == "$": continue
        last_jong = _number_last_jong(num)
        exp = _expected_josa(josa, last_jong)
        original = f"{num}{ws}{josa}"
        corrected = f"{num}{exp}"
        line_num = get_line_number(section_text, m.start())
        if josa != exp or ws:
            errors.append({"location": f"{line_num}í–‰", "original": original, "corrected": corrected, "reason": "ì¡°ì‚¬ ì˜¤ë¥˜(ìˆ«ì)", "severity": "medium"})
    return errors

def _dedup_errors(errors):
    seen = set(); out = []
    for e in errors:
        key = (e.get("original",""), e.get("corrected",""), e.get("reason",""))
        if key in seen: continue
        seen.add(key); out.append(e)
    return out

# ==========================================
# [ë¡œì§ A] LaTeX ZIP ì²˜ë¦¬ ì „ìš©
# ==========================================
def extract_tex_from_zip(zip_file_bytes):
    try:
        with zipfile.ZipFile(zip_file_bytes) as z:
            tex_files = [f for f in z.namelist() if f.lower().endswith('.tex')]
            if not tex_files: return None, "ZIP íŒŒì¼ ë‚´ì— .tex íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
            target_file = tex_files[0]
            try: content = z.read(target_file).decode('utf-8')
            except UnicodeDecodeError: content = z.read(target_file).decode('cp949')
            return content, None
    except Exception as e: return None, f"ZIP ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"

def parse_tex_content(tex_content):
    pattern = r'\\begin\{document\}([\s\S]*?)\\end\{document\}'
    match = re.search(pattern, tex_content)
    body = match.group(1).strip() if match else tex_content
    body = re.sub(r'\\maketitle', '', body)
    body = re.sub(r'\\newpage', '', body)
    body = re.sub(r'\\clearpage', '', body)
    start_pattern = re.compile(r'\\section\*?\{')
    matches = list(start_pattern.finditer(body))
    if not matches: return [body]
    chunks = []
    for i in range(len(matches)):
        start_idx = matches[i].start()
        end_idx = matches[i+1].start() if i + 1 < len(matches) else len(body)
        chunks.append(body[start_idx:end_idx])
    final_items = []
    current_item_text = ""
    explanation_keywords = ["í•´ë²•", "í•´ì„¤", "í’€ì´", "ì •ë‹µ", "Solution", "ì„±ì§ˆ", "ê°œë…", "ì •ë¦¬", "ë¶„ì„", "ì ‘ê·¼", "Note", "Tip", "Guide", "ê³µì‹"]
    ignore_keywords = ["Day", "ì¼ì°¨"] 
    for chunk in chunks:
        brace_open_index = chunk.find('{')
        title_content = ""
        if brace_open_index != -1:
            brace_count = 1
            for k, char in enumerate(chunk[brace_open_index+1:], 1):
                if char == '{': brace_count += 1
                elif char == '}': brace_count -= 1
                if brace_count == 0:
                    title_content = chunk[brace_open_index+1 : brace_open_index+k]
                    break
        is_ignore = any(kw in title_content for kw in ignore_keywords)
        is_explicit_explanation = any(kw in title_content for kw in explanation_keywords)
        has_korean_text = bool(re.search(r'[ê°€-í£]', title_content))
        is_explanation = is_explicit_explanation or (has_korean_text and not is_ignore)
        if is_ignore:
            if current_item_text.strip(): final_items.append(current_item_text.strip())
            current_item_text = ""
            continue
        if is_explanation:
            if current_item_text: current_item_text += "\n" + chunk
            else:
                if final_items: final_items[-1] += "\n" + chunk
                else: current_item_text = chunk
        else:
            if current_item_text.strip(): final_items.append(current_item_text.strip())
            current_item_text = chunk
    if current_item_text.strip(): final_items.append(current_item_text.strip())
    return final_items

def review_tex_section(client, section_text, section_num):
    """[LaTeX ZIP ì „ìš©] Markdown Table í˜•ì‹ ë¦¬í„´"""
    rule_errors = rule_check_josa(section_text)
    prompt = PROMPT_FOR_TEX + "\n\n---------------------------------------------------------\n[ê²€í† í•  í…ìŠ¤íŠ¸]\n" + section_text + "\n---------------------------------------------------------"
    try:
        response = client.models.generate_content(model='gemini-1.5-flash', contents=prompt)
        return {"section": section_num, "rule_errors": rule_errors, "ai_report_text": response.text}
    except Exception as e:
        return {"section": section_num, "rule_errors": rule_errors, "api_error": str(e)}

def generate_report_for_tex(results):
    lines = ["# ğŸ† ì¢…í•© í•™ìˆ  ê°ì‚¬ ë³´ê³ ì„œ\n"]
    for res in results:
        lines.append(f"\n---")
        lines.append(f"## ğŸ“„ ë¬¸í•­ ì„¸íŠ¸ {res['section']}\n")
        if res.get('rule_errors'):
            lines.append("### ğŸ [Python ê·œì¹™ ê°ì§€] (ì°¸ê³ ìš©)")
            lines.append("| ìœ„ì¹˜ | ì˜¤ë¥˜ ë‚´ìš© | ì›ë¬¸ $\\to$ ìˆ˜ì • ì œì•ˆ |")
            lines.append("| :--- | :--- | :--- |")
            for err in res['rule_errors']:
                lines.append(f"| {err['location']} | {err['reason']} | {err['original']} $\\to$ {err['corrected']} |")
            lines.append("\n")
        if 'api_error' in res: lines.append(f"âš ï¸ **API Error:** {res['api_error']}")
        else: lines.append(res['ai_report_text'])
    return "\n".join(lines)


# ==========================================
# [ë¡œì§ B] 2512 PDF ì²˜ë¦¬ ì „ìš©
# ==========================================
def process_pdf(client, pdf_path, progress_callback=None):
    try:
        if POPPLER_PATH: pages = convert_from_path(pdf_path, dpi=300, poppler_path=POPPLER_PATH)
        else: pages = convert_from_path(pdf_path, dpi=300)
    except Exception as e: return None, f"ì˜¤ë¥˜: PDF ë³€í™˜ ì‹¤íŒ¨ ({e})"
    
    full_text = ""
    prompt = """
    ì´ë¯¸ì§€ ë‚´ìš©ì„ Markdownìœ¼ë¡œ ë³€í™˜(OCR)í•˜ì„¸ìš”.
    ìˆ˜ì‹ì€ LaTeX($$)ë¥¼ ì‚¬ìš©í•˜ê³ , í•œê¸€ì€ ì •í™•íˆ ë³´ì¡´í•˜ì„¸ìš”.
    ë¬¸í•­ ë²ˆí˜¸ì™€ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
    """
    total_pages = len(pages)
    for i, page in enumerate(pages):
        if progress_callback: progress_callback(i + 1, total_pages, "ë³€í™˜")
        try:
            img_byte_arr = io.BytesIO()
            page.save(img_byte_arr, format='PNG')
            img_bytes = img_byte_arr.getvalue()
            image_part = types.Part.from_bytes(data=img_bytes, mime_type='image/png')
            response = client.models.generate_content(model='gemini-1.5-flash', contents=[prompt, image_part])
            full_text += f"\n\n--- Page {i+1} ---\n\n" + response.text
            time.sleep(2)
        except Exception as e: full_text += f"\n\n--- Page {i+1} (Error: {e}) ---\n\n"
    return full_text, None

def split_pdf_sections(content):
    sections = re.split(r'\n(?=---\s*Page|\n---\n|\d+\.\s)', content)
    return [s.strip() for s in sections if s.strip()]

def review_pdf_section(client, section_text, section_num):
    """[2512 PDF ì „ìš©] JSON í˜•ì‹ ë¦¬í„´"""
    rule_errors = rule_check_josa(section_text)
    prompt = PROMPT_FOR_PDF.format(section_text=section_text)
    
    try:
        response = client.models.generate_content(model='gemini-1.5-flash', contents=prompt)
        json_str = response.text.strip().replace('```json', '').replace('```', '')
        llm_errors = json.loads(json_str)
        merged = _dedup_errors(rule_errors + (llm_errors or []))
        return {"section": section_num, "errors": merged}
    except json.JSONDecodeError:
        return {"section": section_num, "errors": rule_errors, "parse_error": response.text}
    except Exception as e:
        return {"section": section_num, "errors": rule_errors, "api_error": str(e)}

def generate_report_for_pdf(results):
    report_lines = ["# ğŸ“ ê²€í†  ë³´ê³ ì„œ (2512)\n"]
    total_errors = 0
    for result in results:
        section_num = result["section"]
        errors = result.get("errors", [])
        if "parse_error" in result or "api_error" in result:
            report_lines.append(f"\n## ì„¹ì…˜ {section_num}\nâš ï¸ ì˜¤ë¥˜ ë°œìƒ")
        if errors:
            report_lines.append(f"\n## ì„¹ì…˜ {section_num}\n")
            for err in errors:
                total_errors += 1
                icon = "ğŸ”´" if err.get("severity") == "high" else "ğŸŸ¡"
                report_lines.append(f"### {icon} ì˜¤ë¥˜ {total_errors}")
                report_lines.append(f"- **ì›ë¬¸**: {err.get('original', 'N/A')}")
                report_lines.append(f"- **ìˆ˜ì •**: {err.get('corrected', 'N/A')}")
                report_lines.append(f"- **ì´ìœ **: {err.get('reason', 'N/A')}\n")
    return '\n'.join(report_lines)

# ==========================================
# [í™”ë©´ ì „í™˜ ê´€ë¦¬]
# ==========================================
if 'current_page' not in st.session_state:
    st.session_state.current_page = 'main'

def navigate_to(page):
    st.session_state.current_page = page

# ==========================================
# [í™”ë©´ 1] ë©”ì¸ í˜ì´ì§€ (LaTeX ZIP ìë™í™”)
# ==========================================
def main_page():
    # ìƒë‹¨ í—¤ë” ì˜ì—­ (ìš°ì¸¡ì— 2512 ë²„íŠ¼ ë°°ì¹˜)
    col_title, col_btn = st.columns([8, 1])
    with col_title:
        st.title("ì—…ë¬´ ìë™í™” (LaTeX ZIP)")
    with col_btn:
        # ìš°ìƒë‹¨ êµ¬ì„ 2512 ë²„íŠ¼
        if st.button("2512 â–¶"):
            navigate_to('2512')
            st.rerun()

    st.markdown("""
    **LaTeX ZIP ìë™ ì •ì œ ë° ê²€í†  ì‹œìŠ¤í…œ**ì…ë‹ˆë‹¤.
    1. ë³€í™˜ í”„ë¡œê·¸ë¨ì˜ **ZIP íŒŒì¼**ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.
    2. 'Day' í—¤ë” ì œê±°, **[ë¬¸ì œ+í•´ì„¤]** ìë™ ê·¸ë£¹í™”ê°€ ìˆ˜í–‰ë©ë‹ˆë‹¤.
    3. **í‘œ(Table) í˜•ì‹**ì˜ ì •ë°€ ë¦¬í¬íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """)

    # ì‚¬ì´ë“œë°” (API Key)
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        if 'api_key' not in st.session_state: st.session_state.api_key = DEFAULT_API_KEY
        api_input = st.text_input("Google API Key", value=st.session_state.api_key, type="password")
        st.session_state.api_key = api_input
    
    # ZIP ì—…ë¡œë“œ ë° ì²˜ë¦¬ ë¡œì§
    uploaded_zip = st.file_uploader("ZIP íŒŒì¼ ì—…ë¡œë“œ (.zip)", type=["zip"])
    
    if uploaded_zip:
        with st.spinner("ZIP íŒŒì¼ ë¶„ì„ ì¤‘..."):
            tex_content, error = extract_tex_from_zip(uploaded_zip)
        
        if error:
            st.error(error)
            st.stop()
            
        st.success("âœ… .tex íŒŒì¼ ì¶”ì¶œ ì„±ê³µ!")
        items = parse_tex_content(tex_content)
        st.info(f"ì´ {len(items)}ê°œì˜ ë¬¸í•­ ì„¸íŠ¸ê°€ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        st.subheader("ğŸ” ë¬¸í•­ ì „ì²´ ë³´ê¸°")
        for idx, item in enumerate(items):
            preview_title = item[:50].replace('\n', ' ') + "..."
            with st.expander(f"ë¬¸í•­ {idx+1}: {preview_title}"):
                st.code(item, language='latex')

        if st.button("ğŸš€ AI í•™ìˆ  ê°ì‚¬ ì‹œì‘", type="primary"):
            if not st.session_state.api_key:
                st.error("API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                st.stop()
            
            client = genai.Client(api_key=st.session_state.api_key)
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            all_results = []
            for i, item_text in enumerate(items):
                status_text.text(f"ê°ì‚¬ê´€ ê²€í†  ì¤‘... ({i+1}/{len(items)})")
                progress_bar.progress((i + 1) / len(items))
                
                # ì¬ì‹œë„ ë¡œì§
                max_retries = 3; retry_delay = 5
                for attempt in range(max_retries):
                    result = review_tex_section(client, item_text, i + 1)
                    if "api_error" in result and "429" in str(result["api_error"]):
                        if attempt < max_retries - 1:
                            time.sleep(retry_delay); retry_delay *= 2
                            continue
                    all_results.append(result)
                    break
                time.sleep(2) 
            
            report = generate_report_for_tex(all_results)
            st.divider()
            st.subheader("ğŸ“‹ ê°ì‚¬ ê²°ê³¼ ë³´ê³ ì„œ")
            st.markdown(report)
            st.download_button("ğŸ“¥ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ", report, file_name="auditor_report_v8.1.md")
            st.success("ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

# ==========================================
# [í™”ë©´ 2] 2512 í˜ì´ì§€ (Legacy PDF)
# ==========================================
def page_2512():
    if st.button("â† ë©”ì¸ìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        navigate_to('main')
        st.rerun()
    st.divider()
    
    st.title("ìˆ˜í•™ êµì¬ PDF ë³€í™˜ & ê²€í†  (2512)")
    st.info("ê¸°ì¡´ PDF OCR ë° JSON ê¸°ë°˜ ê²€í†  ê¸°ëŠ¥ì…ë‹ˆë‹¤.")

    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì • (2512)")
        if 'api_key' not in st.session_state: st.session_state.api_key = DEFAULT_API_KEY
        api_input = st.text_input("Google API Key", value=st.session_state.api_key, type="password")
        st.session_state.api_key = api_input
        st.divider()
        do_convert = st.checkbox("1ë‹¨ê³„: PDF â†’ Markdown ë³€í™˜", value=True)
        do_review = st.checkbox("2ë‹¨ê³„: Markdown ê²€í† ", value=True)

    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜ ì„ íƒí•˜ì„¸ìš”", type=["pdf"])

    if uploaded_file is not None:
        if st.button("ğŸš€ ì‹œì‘í•˜ê¸°", type="primary"):
            if not st.session_state.api_key:
                st.error("âŒ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                st.stop()
            
            client = genai.Client(api_key=st.session_state.api_key)
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            def update_progress(current, total, stage):
                progress_bar.progress(current / total)
                status_text.text(f"[{stage}] {current}/{total} ì²˜ë¦¬ ì¤‘...")
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_path = tmp_file.name
            
            try:
                converted_text = None
                if do_convert:
                    st.subheader("ğŸ“„ 1ë‹¨ê³„: PDF â†’ Markdown ë³€í™˜")
                    converted_text, error = process_pdf(client, tmp_path, update_progress)
                    if error: st.error(error); st.stop()
                    st.text_area("ë³€í™˜ ê²°ê³¼", converted_text, height=300)
                    st.download_button("ğŸ“¥ ë³€í™˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", converted_text, file_name="converted.md")

                if do_review and converted_text:
                    st.subheader("ğŸ“‹ 2ë‹¨ê³„: Markdown ê²€í† ")
                    sections = split_pdf_sections(converted_text)
                    all_results = []
                    total = len(sections)
                    for i, section in enumerate(sections):
                        update_progress(i+1, total, "ê²€í† ")
                        # 2512 ì „ìš© ê²€í†  í•¨ìˆ˜ ì‚¬ìš©
                        res = review_pdf_section(client, section, i+1)
                        all_results.append(res)
                        time.sleep(2)
                    
                    report = generate_report_for_pdf(all_results)
                    st.text_area("ê²€í†  ë³´ê³ ì„œ", report, height=300)
                    st.download_button("ğŸ“¥ ê²€í†  ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ", report, file_name="report_2512.md")
                    st.success("ì™„ë£Œ!")
                    
            finally:
                if os.path.exists(tmp_path): os.remove(tmp_path)

# ==========================================
# [ì•± ì‹¤í–‰ ì§„ì…ì ]
# ==========================================
if st.session_state.current_page == 'main':
    main_page()
elif st.session_state.current_page == '2512':
    page_2512()
