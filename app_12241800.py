import streamlit as st
import os
import io
import tempfile
import time
import json
import re
from google import genai
from google.genai import types
from pdf2image import convert_from_path

# ==========================================
# [ê¸°ë³¸ ì„¤ì •]
# ==========================================
DEFAULT_API_KEY = ""

# í™˜ê²½ì— ë”°ë¼ Poppler ê²½ë¡œ ì„¤ì •
if os.name == 'nt':  # Windows (ë¡œì»¬)
    POPPLER_PATH = r"C:\Users\inter\Desktop\Review\poppler-25.12.0\Library\bin"
else:  # Linux (Streamlit Cloud)
    POPPLER_PATH = None

REVIEW_CRITERIA = """
1. **ì¡°ì‚¬ ì—°ê²°**: ìˆ˜ì‹ ë’¤ì˜ ì¡°ì‚¬($f(x)$ëŠ”/ì€ ë“±)ê°€ ìì—°ìŠ¤ëŸ¬ìš´ì§€
2. **ë§ì¶¤ë²•/ë„ì–´ì“°ê¸°**: ê¸°ë³¸ì ì¸ í•œêµ­ì–´ ë§ì¶¤ë²• ì¤€ìˆ˜
3. **í”¼ë™/ì‚¬ë™**: 'ë˜ì–´ì§€ë‹¤', 'ë³´ì—¬ì§€ë‹¤' ë“± ì´ì¤‘ í”¼ë™ ì§€ì–‘
4. **ëŒ€ë“± ì—°ê²°**: ë¬¸ì¥ ë‚˜ì—´ ì‹œ êµ¬ì¡°ì  ëŒ€ë“±ì„± ìœ ì§€
5. **ì£¼ìˆ  í˜¸ì‘**: ì£¼ì–´ì™€ ì„œìˆ ì–´ì˜ ê´€ê³„ê°€ ëª…í™•í•œì§€
6. **ì¤‘ì˜ì„±**: í•´ì„ì´ ëª¨í˜¸í•œ ë¬¸ì¥ ìˆ˜ì •
7. **ìˆ˜í•™ ìš©ì–´**: ê³ êµ ê³¼ì •ì— ë§ëŠ” ì •í™•í•œ ìš©ì–´ ì‚¬ìš©
8. **ë³€ìˆ˜ ì¼ê´€ì„±**: ì •ì˜ëœ ë³€ìˆ˜ê°€ ëê¹Œì§€ ìœ ì§€ë˜ëŠ”ì§€
9. **ì˜¤íƒ€**: ë‹¨ìˆœ ì˜¤íƒ€ ë° OCR ì˜¤ë¥˜
"""

# ==========================================
# [ì¡°ì‚¬ ê·œì¹™ ê¸°ë°˜ ê²€ì‚¬]
#  - LLMì´ ë†“ì¹˜ê¸° ì‰¬ìš´ 'ìˆ˜ì‹/ìˆ«ì/ê´„í˜¸ ë’¤ ì¡°ì‚¬'ë¥¼ ì½”ë“œë¡œ 1ì°¨ ê²€ì¶œí•©ë‹ˆë‹¤.
# ==========================================

# ì¢…ì„±(ë°›ì¹¨) í…Œì´ë¸” (ìœ ë‹ˆì½”ë“œ í•œê¸€ ìŒì ˆ ë¶„í•´ìš©)
_JONGSUNG_LIST = [
    "", "ã„±", "ã„²", "ã„³", "ã„´", "ã„µ", "ã„¶", "ã„·", "ã„¹", "ã„º", "ã„»", "ã„¼", "ã„½", "ã„¾", "ã„¿", "ã…€",
    "ã…", "ã…‚", "ã…„", "ã……", "ã…†", "ã…‡", "ã…ˆ", "ã…Š", "ã…‹", "ã…Œ", "ã…", "ã…"
]

# ì•ŒíŒŒë²³(ë³€ìˆ˜) ë°œìŒì˜ ë§ˆì§€ë§‰ ë°›ì¹¨(í•„ìš”í•œ ê²ƒë§Œ)
_LATIN_LAST_JONG = {
    "A": "", "B": "", "C": "", "D": "", "E": "", "F": "", "G": "", "H": "", "I": "", "J": "", "K": "",
    "L": "ã„¹", "M": "ã…", "N": "ã„´", "O": "", "P": "", "Q": "", "R": "ã„¹", "S": "", "T": "", "U": "",
    "V": "", "W": "", "X": "", "Y": "", "Z": ""
}

# ê·¸ë¦¬ìŠ¤ ë¬¸ì(ê¸°ë³¸ì ìœ¼ë¡œ ë°›ì¹¨ ì—†ìŒ: ì•ŒíŒŒ/ë² íƒ€/ê°ë§ˆ/... ë§ˆì§€ë§‰ ìŒì ˆì´ ëŒ€ë¶€ë¶„ ëª¨ìŒ ì¢…ê²°)
_GREEK_MACRO_LAST_JONG = {
    "alpha": "", "beta": "", "gamma": "", "delta": "", "epsilon": "", "zeta": "", "eta": "", "theta": "",
    "iota": "", "kappa": "", "lambda": "", "mu": "", "nu": "", "xi": "", "omicron": "", "pi": "", "rho": "",
    "sigma": "", "tau": "", "upsilon": "", "phi": "", "chi": "", "psi": "", "omega": "",
    # ìì£¼ ë“±ì¥í•˜ëŠ” íŠ¹ìˆ˜
    "ell": "ã„¹",  # \ell -> 'ì—˜'
}

# ìˆ«ì í•œììŒ ì½ê¸°ì˜ ë§ˆì§€ë§‰ ë°›ì¹¨ ì¶”ì •ìš©(1=ì¼, 3=ì‚¼, 7=ì¹ , 8=íŒ”, 9=êµ¬, 0=ì˜/ê³µ)
_DIGIT_LAST_JONG = {  # ë§ˆì§€ë§‰ ë°›ì¹¨(ì¢…ì„±)
    "0": "ã…‡",  # ì˜/ê³µ
    "1": "ã„¹",  # ì¼
    "2": "",    # ì´
    "3": "ã…",  # ì‚¼
    "4": "",    # ì‚¬
    "5": "",    # ì˜¤
    "6": "ã„±",  # ìœ¡
    "7": "ã„¹",  # ì¹ 
    "8": "ã„¹",  # íŒ”
    "9": "",    # êµ¬
}

_UNIT_LAST_JONG = {
    "ì‹­": "ã…‚",
    "ë°±": "ã„±",
    "ì²œ": "ã„´",
    "ë§Œ": "ã„´",
    "ì–µ": "ã„±",
    "ì¡°": "",   # ì¡°(ë°›ì¹¨ ì—†ìŒ)ë¡œ ì·¨ê¸‰
    "ê²½": "ã…‡",
}
_GROUP_UNITS = ["", "ë§Œ", "ì–µ", "ì¡°", "ê²½"]

_JOSA_CANDIDATES = ("ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ê³¼", "ì™€", "ìœ¼ë¡œ", "ë¡œ")

# ì •ê·œì‹: (1) ìˆ˜ì‹($...$) + ì¡°ì‚¬, (2) ìˆ«ì + ì¡°ì‚¬, (3) (ë‹¨ì–´)(...)+ì¡°ì‚¬
_MATH_JOSA_PATTERN = re.compile(
    r'(?P<math>\${1,2}[^$]+?\${1,2})(?P<ws>\s*)(?P<josa>ìœ¼ë¡œ|ë¡œ|ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ê³¼|ì™€)'
    r'(?=[\s\.,;:\)\]\}\!?]|$)'
)
_NUM_JOSA_PATTERN = re.compile(
    r'(?P<num>\d[\d,]*(?:\.\d+)?)(?P<ws>\s*)(?P<josa>ìœ¼ë¡œ|ë¡œ|ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ê³¼|ì™€)'
    r'(?=[\s\.,;:\)\]\}\!?]|$)'
)
_PAREN_JOSA_PATTERN = re.compile(
    r'(?P<head>[ê°€-í£]+)\s*\(\s*(?P<inner>[^)\n]{1,120}?)\s*\)(?P<ws>\s*)(?P<josa>ìœ¼ë¡œ|ë¡œ|ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ê³¼|ì™€)'
    r'(?=[\s\.,;:\)\]\}\!?]|$)'
)

# í•´ì„¤/í’€ì´/ì •ë‹µ ë“± ê²½ê³„ ì¶”ì •ìš©(ì„¹ì…˜ ë‚´ì—ì„œ ì´ ë¬¸ìì—´ ì´í›„ë¥¼ 'í•´ì„¤'ë¡œ ê°„ì£¼)
_EXPLANATION_MARKERS = ("í•´ì„¤", "í’€ì´", "í•´ë²•", "ì •ë‹µ", "í•´ë‹µ", "Solution", "í•´ì„¤)", "í’€ì´)")

def _hangul_last_jong(text: str) -> str:
    """ë¬¸ìì—´ì˜ ë§ˆì§€ë§‰ 'ë°œìŒ ê°€ëŠ¥í•œ' í•œê¸€ ìŒì ˆì˜ ì¢…ì„±ì„ ë°˜í™˜(""ì´ë©´ ë°›ì¹¨ ì—†ìŒ)."""
    if not text:
        return ""
    # ëì˜ ê³µë°±/êµ¬ë‘ì  ì œê±°
    s = re.sub(r'[\s\.,;:!\?\)\]\}]+$', '', text.strip())
    for ch in reversed(s):
        code = ord(ch)
        if 0xAC00 <= code <= 0xD7A3:  # ê°€-í£
            jong = (code - 0xAC00) % 28
            return _JONGSUNG_LIST[jong]
    return ""

def _latin_last_jong(text: str) -> str:
    s = text.strip()
    if not s:
        return ""
    # ë§ˆì§€ë§‰ ì•ŒíŒŒë²³ ë¬¸ì ì°¾ê¸°
    for ch in reversed(s):
        if ch.isalpha():
            return _LATIN_LAST_JONG.get(ch.upper(), "")
    return ""

def _number_last_jong(num_raw: str) -> str:
    """ì•„ë¼ë¹„ì•„ ìˆ«ìë¥¼ í•œììŒìœ¼ë¡œ ì½ì—ˆì„ ë•Œ ë§ˆì§€ë§‰ ì¢…ì„±ì„ ëŒ€ëµ ì¶”ì •."""
    if not num_raw:
        return ""
    s = num_raw.strip()

    # ìˆ˜ì‹ í˜•íƒœ($3$)ë„ ì…ë ¥ë  ìˆ˜ ìˆì–´ ë°©ì–´
    if s.startswith("$") and s.endswith("$") and len(s) >= 3:
        s = s[1:-1].strip()

    s = s.replace(",", "").replace(" ", "")
    s = s.lstrip("+")
    if s.startswith(("-", "âˆ’")):
        s = s[1:]

    if not s:
        return ""

    # ì†Œìˆ˜: ë§ˆì§€ë§‰ ì†Œìˆ˜ ìë¦¿ìˆ˜ ìˆ«ì ê¸°ì¤€(3.1 -> 'ì¼' -> ã„¹)
    if "." in s:
        left, right = s.split(".", 1)
        right_digits = re.sub(r"\D", "", right)
        if right_digits:
            return _DIGIT_LAST_JONG.get(right_digits[-1], "")
        s = left

    digits = re.sub(r"\D", "", s)
    if not digits:
        return ""

    # ëª¨ë‘ 0ì´ë©´ 'ì˜/ê³µ'
    if set(digits) == {"0"}:
        return _DIGIT_LAST_JONG["0"]

    digits = digits.lstrip("0") or "0"

    # 4ìë¦¬ ê·¸ë£¹(ë§Œ/ì–µ/ì¡°/ê²½) ë‹¨ìœ„ ê¸°ë°˜
    groups = []
    tmp = digits
    while tmp:
        groups.append(tmp[-4:].rjust(4, "0"))
        tmp = tmp[:-4]

    low = groups[0]
    if int(low) != 0:
        thousands, hundreds, tens, ones = low
        if ones != "0":
            return _DIGIT_LAST_JONG.get(ones, "")
        if tens != "0":
            return _UNIT_LAST_JONG["ì‹­"]
        if hundreds != "0":
            return _UNIT_LAST_JONG["ë°±"]
        return _UNIT_LAST_JONG["ì²œ"]

    # í•˜ìœ„ 4ìë¦¬ê°€ 0ì´ë©´ ê°€ì¥ ë‚®ì€ ë¹„0 ê·¸ë£¹ì˜ ë‹¨ìœ„ë¥¼ ë§ˆì§€ë§‰ìœ¼ë¡œ ë°œìŒí•œë‹¤ê³  ê°€ì •
    for idx in range(1, len(groups)):
        if int(groups[idx]) != 0:
            unit = _GROUP_UNITS[idx] if idx < len(_GROUP_UNITS) else _GROUP_UNITS[-1]
            return _UNIT_LAST_JONG.get(unit, "")
    return _DIGIT_LAST_JONG["0"]

def _expected_josa(josa: str, last_jong: str) -> str:
    """ë°›ì¹¨(last_jong)ì— ë”°ë¥¸ ê¸°ëŒ€ ì¡°ì‚¬."""
    has_batchim = (last_jong != "")
    if josa in ("ì€", "ëŠ”"):
        return "ì€" if has_batchim else "ëŠ”"
    if josa in ("ì´", "ê°€"):
        return "ì´" if has_batchim else "ê°€"
    if josa in ("ì„", "ë¥¼"):
        return "ì„" if has_batchim else "ë¥¼"
    if josa in ("ê³¼", "ì™€"):
        return "ê³¼" if has_batchim else "ì™€"
    if josa in ("ìœ¼ë¡œ", "ë¡œ"):
        # ë°›ì¹¨ ì—†ê±°ë‚˜ ã„¹ë°›ì¹¨ì´ë©´ 'ë¡œ'
        return "ë¡œ" if (not has_batchim or last_jong == "ã„¹") else "ìœ¼ë¡œ"
    return josa

def _strip_math_delimiters(math: str) -> str:
    s = math.strip()
    if s.startswith("$$") and s.endswith("$$") and len(s) >= 4:
        return s[2:-2].strip()
    if s.startswith("$") and s.endswith("$") and len(s) >= 2:
        return s[1:-1].strip()
    return s

def _latex_extract_last_atom(latex: str) -> str:
    """LaTeX ìˆ˜ì‹ì—ì„œ 'ë§ˆì§€ë§‰ìœ¼ë¡œ ë°œìŒë  ê°€ëŠ¥ì„±ì´ ë†’ì€ ì›ì'ë¥¼ ëŒ€ëµ ì¶”ì¶œ."""
    s = latex.strip()

    # í”í•œ ì¥ì‹/êµ¬ë¶„ ëª…ë ¹ ì œê±°
    s = re.sub(r"\\(left|right)\b", "", s)

    # ëì˜ ë¶ˆí•„ìš” ê¸°í˜¸ ì œê±°
    while True:
        new_s = re.sub(r"[\s\.,;:!\?\)\]\}]+$", "", s)
        new_s = re.sub(r"(\\,|\\;|\\:|\\!|\\quad|\\qquad)\s*$", "", new_s)
        new_s = re.sub(r"(\\cdot|\\times|\\pm|\\mp|\\div)\s*$", "", new_s)
        if new_s == s:
            break
        s = new_s

    # í•˜ì²¨ì/ìœ—ì²¨ìê°€ ë¬¸ì¥ ëì— ì˜¤ëŠ” ê²½ìš°: a_1, a_{1}, x^2 ë“±
    m = re.search(r"(?:_|\^)(\{([^{}]{1,40})\}|([A-Za-z0-9]))\s*$", s)
    if m:
        inner = m.group(2) or m.group(3) or ""
        return inner.strip()

    # \frac{A}{B}ê°€ ëì— ì˜¤ëŠ” ê²½ìš° -> ë³´í†µ 'Bë¶„ì˜A'ë¡œ ì½ìœ¼ë¯€ë¡œ ë ë°œìŒì€ Aë¡œ ê°€ì •
    m = re.search(r"\\frac\s*\{([^{}]{1,80})\}\s*\{([^{}]{1,80})\}\s*$", s)
    if m:
        return (m.group(1) or "").strip()

    # \sqrt{...}ê°€ ëì— ì˜¤ëŠ” ê²½ìš° -> 'ë£¨íŠ¸ ...'ë¡œ ì½ê³  ë§ˆì§€ë§‰ì€ ì•ˆìª½ìœ¼ë¡œ ê°€ì •
    m = re.search(r"\\sqrt\s*\{([^{}]{1,80})\}\s*$", s)
    if m:
        return (m.group(1) or "").strip()

    # ë§¤í¬ë¡œ(\alpha ë“±)ë¡œ ëë‚˜ëŠ” ê²½ìš°
    m = re.search(r"\\([A-Za-z]+)\s*$", s)
    if m:
        return "\\" + m.group(1)

    # ê´„í˜¸ë¡œ ëë‚˜ë©´ ê´„í˜¸ëŠ” ì½ì§€ ì•ŠëŠ”ë‹¤ê³  ë³´ê³  ì œê±° í›„ ì¬ê·€ì ìœ¼ë¡œ ì¶”ì¶œ
    if s.endswith((")", "]")):
        return _latex_extract_last_atom(s[:-1])

    # ì¤‘ê´„í˜¸ë¡œ ëë‚˜ë©´ ë²—ê²¨ë³´ê³  ì¬ê·€
    if s.endswith("}"):
        return _latex_extract_last_atom(s[:-1])

    # ê¸°ë³¸: ë§ˆì§€ë§‰ í† í°(ìˆ«ì/ì˜ë¬¸/í•œê¸€) ì¶”ì¶œ
    m = re.search(r"([0-9][0-9,]*(?:\.[0-9]+)?|[A-Za-z]+|[ê°€-í£]+)\s*$", s)
    if m:
        return m.group(1)

    return ""

def _last_jong_from_math(math: str) -> str:
    latex = _strip_math_delimiters(math)
    atom = _latex_extract_last_atom(latex)
    if not atom:
        return ""

    # ë§¤í¬ë¡œ(\alpha ë“±)
    if atom.startswith("\\"):
        name = atom[1:]
        return _GREEK_MACRO_LAST_JONG.get(name, "")

    # ìˆ«ì
    if re.fullmatch(r"\d[\d,]*(?:\.\d+)?", atom):
        return _number_last_jong(atom)

    # ì•ŒíŒŒë²³
    if re.fullmatch(r"[A-Za-z]+", atom):
        return _latin_last_jong(atom)

    # í•œê¸€
    if re.search(r"[ê°€-í£]", atom):
        return _hangul_last_jong(atom)

    # ê·¸ ì™¸: ë§¨ ëì˜ ìˆ«ì/ì˜ë¬¸/í•œê¸€ì„ ë‹¤ì‹œ íƒìƒ‰
    return _last_jong_from_text(atom)

def _last_jong_from_text(text: str) -> str:
    """ì¼ë°˜ í…ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ ë°œìŒ ìš”ì†Œ(í•œê¸€/ìˆ«ì/ì•ŒíŒŒë²³/ìˆ˜ì‹)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¢…ì„± ì¶”ì •."""
    if not text:
        return ""
    s = text.strip()

    # ê´„í˜¸/ëŒ€ê´„í˜¸/ì¸ìš©ë¶€í˜¸ ë“± ë ê¸°í˜¸ ì œê±°
    s = re.sub(r"[\s\.,;:!\?\)\]\}\>\"]+$", "", s)
    if not s:
        return ""

    # ìˆ˜ì‹($...$)ë¡œ ëë‚˜ë©´ ìˆ˜ì‹ ê¸°ì¤€
    m = re.search(r"(\${1,2}[^$]+?\${1,2})\s*$", s)
    if m:
        return _last_jong_from_math(m.group(1))

    # ìˆ«ìë¡œ ëë‚˜ë©´
    m = re.search(r"(\d[\d,]*(?:\.\d+)?)\s*$", s)
    if m:
        return _number_last_jong(m.group(1))

    # í•œê¸€ë¡œ ëë‚˜ë©´
    jong = _hangul_last_jong(s)
    if jong != "" or re.search(r"[ê°€-í£]$", s):
        return jong

    # ì•ŒíŒŒë²³ìœ¼ë¡œ ëë‚˜ë©´
    m = re.search(r"([A-Za-z]+)\s*$", s)
    if m:
        return _latin_last_jong(m.group(1))

    return ""

def _is_internal_reference(inner: str) -> bool:
    """ê°ì£¼/êµì¬ ë‚´ë¶€ ì°¸ì¡°/í˜ì´ì§€ í‘œê¸° ë“±ì€ 'ì½ì§€ ì•ŠëŠ”ë‹¤'ë¡œ ì²˜ë¦¬."""
    if not inner:
        return False
    s = inner.strip()

    # page í‘œê¸°(ì˜ˆ: 218p, p.218, 218ìª½)
    if re.search(r"\b\d+\s*p\b", s, flags=re.IGNORECASE):
        return True
    if re.search(r"\bp\.?\s*\d+\b", s, flags=re.IGNORECASE):
        return True
    if re.search(r"\b\d+\s*ìª½\b", s):
        return True
    if re.search(r"\bpage\s*\d+\b", s, flags=re.IGNORECASE):
        return True

    # í”í•œ êµì¬ ì°¸ì¡° í‚¤ì›Œë“œ
    keywords = ("í‰ìˆ˜ëŠ¥", "ìˆ˜ëŠ¥", "ê¸°ì¶œ", "í™•í†µ", "ë¯¸ì ", "ê¸°í•˜", "êµì¬", "ì°¸ê³ ", "ì˜ˆì œ", "ë¬¸í•­", "ì •ë‹µ", "í•´ì„¤", "í’€ì´")
    if any(k in s for k in keywords):
        return True

    return False

def _infer_section_context(section_text: str, pos: int) -> str:
    """ì„¹ì…˜ ë‚´ì—ì„œ 'í•´ì„¤/í’€ì´/ì •ë‹µ' ë§ˆì»¤ ì´í›„ë©´ explanation, ê·¸ ì „ì´ë©´ problemë¡œ ê°„ì£¼."""
    hits = [section_text.find(m) for m in _EXPLANATION_MARKERS if section_text.find(m) != -1]
    if hits:
        boundary = min(hits)
        return "explanation" if pos >= boundary else "problem"

    # ë§ˆì»¤ê°€ ì—†ì„ ë•ŒëŠ” ì„¹ì…˜ ì´ˆë°˜ì˜ ì‹ í˜¸ë¡œ ë¬¸ì œ/í•´ì„¤ì„ ì¶”ì •í•©ë‹ˆë‹¤.
    # (ë¬¸ì œ) ì„ ì§€(â‘ ~â‘¤), "ë³´ê¸°", "ë‹¤ìŒ" ë“±ì´ ìˆìœ¼ë©´ ë¬¸ì œì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
    head_chunk = section_text[:300]
    problem_signals = ("ë³´ê¸°", "â‘ ", "â‘¡", "â‘¢", "â‘£", "â‘¤", "ë¬¸ì œ", "ë‹¤ìŒ")
    if any(sig in head_chunk for sig in problem_signals):
        return "problem"

    # ê·¸ ì™¸ì—ëŠ” ê¸°ë³¸ì„ í•´ì„¤ë¡œ ê°„ì£¼(ê´„í˜¸ëŠ” ë¶€ì—° ì„¤ëª…ìœ¼ë¡œ ì·¨ê¸‰)
    return "explanation"

def _should_read_parenthetical(head: str, inner: str, context: str) -> bool:
    """ê´„í˜¸(...) ì•ˆì„ ë°œìŒì— í¬í•¨í• ì§€ ê²°ì •."""
    if _is_internal_reference(inner):
        return False
    if context == "problem":
        return True

    # explanation: ê¸°ë³¸ì€ 'ê´„í˜¸ëŠ” ì½ì§€ ì•ŠìŒ' (ë¶€ì—° ì„¤ëª…ìœ¼ë¡œ ì·¨ê¸‰)
    # ë‹¨, 'ì¡°ê±´/ì •ì˜'ë¡œ ë³´ì´ëŠ” ê²½ìš°ë§Œ ì½ìŒ
    s = inner.strip()

    # ë‹¨ìˆœ '=0' ê°™ì€ í‘œê¸°ëŠ” ëŒ€ë¶€ë¶„ ë¶€ì—°ì´ë¯€ë¡œ ì½ì§€ ì•ŠìŒ
    if re.fullmatch(r"=\s*[-+]?\d+(?:\.\d+)?", s):
        return False

    # ë¶€ë“±ì‹/ë²”ìœ„/ì¡°ê±´ìœ¼ë¡œ ë³´ì´ëŠ” íŒ¨í„´ì€ ì½ìŒ
    if re.search(r"(<=|>=|<|>|â‰¤|â‰¥|\\le|\\ge|\\lt|\\gt)", s):
        return True
    # ë³€ìˆ˜/ì‹ = ê°’ í˜•íƒœ(ë³€ìˆ˜ê°€ í¬í•¨ëœ ë“±ì‹)ëŠ” ì½ìŒ (x=0, f(x)=0 ë“±)
    if re.search(r"[A-Za-zê°€-í£][^=]{0,10}=\s*[-+]?\d", s):
        return True
    if "$" in s or "\\" in s:
        # LaTeX ì¡°ê°ì´ ìˆìœ¼ë©´ ì¡°ê±´/ì •ì˜ì¼ ê°€ëŠ¥ì„±ì´ ë†’ì•„ ì½ìŒ
        return True

    return False

def rule_check_josa(section_text: str):
    """ì„¹ì…˜ í…ìŠ¤íŠ¸ì—ì„œ ì¡°ì‚¬ ì˜¤ë¥˜(íŠ¹íˆ ìˆ˜ì‹/ìˆ«ì/ê´„í˜¸)ë¥¼ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ê²€ì¶œ."""
    errors = []

    # 1) ìˆ˜ì‹($...$) ë’¤ ì¡°ì‚¬
    for m in _MATH_JOSA_PATTERN.finditer(section_text):
        math = m.group("math")
        ws = m.group("ws") or ""
        josa = m.group("josa")
        last_jong = _last_jong_from_math(math)
        exp = _expected_josa(josa, last_jong)

        original = f"{math}{ws}{josa}"
        corrected = f"{math}{exp}"

        if josa != exp or ws:
            severity = "high" if josa != exp else "medium"
            reason = "1. ì¡°ì‚¬ ì—°ê²°: ìˆ˜ì‹ì˜ ë§ˆì§€ë§‰ ë°œìŒ ìš”ì†Œ(ìˆ«ì/ë³€ìˆ˜/ì²¨ì ë“±) ê¸°ì¤€ìœ¼ë¡œ ì¡°ì‚¬ ì„ íƒ ë° ì¡°ì‚¬ ë¶™ì—¬ì“°ê¸°"
            errors.append({
                "original": original,
                "corrected": corrected,
                "reason": reason,
                "severity": severity
            })

    # 2) ìˆ«ì ë’¤ ì¡°ì‚¬(ì˜ˆ: 3ë¥¼ -> 3ì„). ë‹¨, ìˆ˜ì‹ ë‚´ë¶€ëŠ” ëŒ€ë¶€ë¶„ $...$ë¡œ ê°ì‹¸ì ¸ ìˆìœ¼ë¯€ë¡œ ì¤‘ë³µ ê°€ëŠ¥ì„± ë‚®ìŒ.
    for m in _NUM_JOSA_PATTERN.finditer(section_text):
        num = m.group("num")
        ws = m.group("ws") or ""
        josa = m.group("josa")

        # ë°”ë¡œ ì•ì´ $ì´ë©´($3$ ê°™ì€) ìˆ˜ì‹ ì¼€ì´ìŠ¤ë¡œ ì´ë¯¸ ì²˜ë¦¬í–ˆì„ ê°€ëŠ¥ì„±ì´ ì»¤ì„œ ìŠ¤í‚µ
        if m.start() > 0 and section_text[m.start() - 1] == "$":
            continue

        last_jong = _number_last_jong(num)
        exp = _expected_josa(josa, last_jong)

        original = f"{num}{ws}{josa}"
        corrected = f"{num}{exp}"

        if josa != exp or ws:
            severity = "high" if josa != exp else "medium"
            reason = "1. ì¡°ì‚¬ ì—°ê²°: ìˆ«ìëŠ” í•œììŒ(1=ì¼,2=ì´,3=ì‚¼...)ìœ¼ë¡œ ì½ê³  ë°›ì¹¨ì— ë”°ë¼ ì¡°ì‚¬ ì„ íƒ ë° ì¡°ì‚¬ ë¶™ì—¬ì“°ê¸°"
            errors.append({
                "original": original,
                "corrected": corrected,
                "reason": reason,
                "severity": severity
            })

    # 3) (ë‹¨ì–´)(...) ë’¤ ì¡°ì‚¬: ê´„í˜¸ ë‚´ìš©ì„ ì½ì„ì§€ ì—¬ë¶€ì— ë”°ë¼ íŒë‹¨
    for m in _PAREN_JOSA_PATTERN.finditer(section_text):
        head = m.group("head")
        inner = m.group("inner")
        ws = m.group("ws") or ""
        josa = m.group("josa")

        context = _infer_section_context(section_text, m.start())
        read_inner = _should_read_parenthetical(head, inner, context)

        basis_text = inner if read_inner else head
        last_jong = _last_jong_from_text(basis_text)
        exp = _expected_josa(josa, last_jong)

        original = f"{head}({inner}){ws}{josa}"
        corrected = f"{head}({inner}){exp}"

        if josa != exp or ws:
            severity = "high" if josa != exp else "medium"
            if _is_internal_reference(inner):
                why = "1. ì¡°ì‚¬ ì—°ê²°: ê´„í˜¸ ì•ˆ êµì¬ ì°¸ì¡°/ê°ì£¼ í‘œê¸°ëŠ” ì½ì§€ ì•Šê³  ì• ë‹¨ì–´ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì‚¬ ì„ íƒ"
            elif context == "problem":
                why = "1. ì¡°ì‚¬ ì—°ê²°: [ë¬¸ì œ]ì—ì„œëŠ” ê´„í˜¸ ì•ˆ ë‚´ìš©ë„ ì½ëŠ” ê²ƒìœ¼ë¡œ ë³´ê³  ì¡°ì‚¬ ì„ íƒ"
            else:
                why = "1. ì¡°ì‚¬ ì—°ê²°: [í•´ì„¤]ì—ì„œëŠ” ë¶€ì—° ì„¤ëª… ê´„í˜¸ëŠ” ì½ì§€ ì•Šê³ , ì¡°ê±´/ì •ì˜ ê´„í˜¸ë§Œ ì½ëŠ” ê²ƒìœ¼ë¡œ ë³´ê³  ì¡°ì‚¬ ì„ íƒ"
            errors.append({
                "original": original,
                "corrected": corrected,
                "reason": why,
                "severity": severity
            })

    return errors

def _dedup_errors(errors):
    """ì›ë¬¸/ìˆ˜ì •/ì´ìœ ê°€ ë™ì¼í•œ í•­ëª©ì„ ì¤‘ë³µ ì œê±°."""
    seen = set()
    out = []
    for e in errors:
        key = (e.get("original",""), e.get("corrected",""), e.get("reason",""))
        if key in seen:
            continue
        seen.add(key)
        out.append(e)
    return out


# ==========================================
# [PDF â†’ Markdown ë³€í™˜ í•¨ìˆ˜]
# ==========================================
def process_pdf(client, pdf_path, progress_callback=None):
    """PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ê³  Geminië¡œ OCR ìˆ˜í–‰"""
    
    try:
        if POPPLER_PATH:
            pages = convert_from_path(pdf_path, dpi=300, poppler_path=POPPLER_PATH)
        else:
            pages = convert_from_path(pdf_path, dpi=300)
    except Exception as e:
        return None, f"ì˜¤ë¥˜: PDF ë³€í™˜ ì‹¤íŒ¨ ({e})"
    
    full_text = ""
    prompt = """
    ë‹¹ì‹ ì€ ìˆ˜í•™ êµì¬ë¥¼ ë””ì§€í„¸í™”í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì œê³µëœ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ì •í™•í•˜ê²Œ ë³€í™˜(OCR)í•˜ì„¸ìš”.

    [ì¤‘ìš”: ì½ê¸° ìˆœì„œ]
    ì´ ë¬¸ì„œëŠ” **2ë‹¨ ë ˆì´ì•„ì›ƒ**ì…ë‹ˆë‹¤.
    ë°˜ë“œì‹œ ë‹¤ìŒ ìˆœì„œë¡œ ì½ìœ¼ì„¸ìš”:
    1. ì™¼ìª½ ë‹¨ ì „ì²´ (ìƒë‹¨ â†’ í•˜ë‹¨)
    2. ê·¸ ë‹¤ìŒ ì˜¤ë¥¸ìª½ ë‹¨ ì „ì²´ (ìƒë‹¨ â†’ í•˜ë‹¨)

    ì ˆëŒ€ë¡œ ì™¼ìª½-ì˜¤ë¥¸ìª½ì„ ë²ˆê°ˆì•„ê°€ë©° ì½ì§€ ë§ˆì„¸ìš”.

    [ì§€ì¹¨]
    1. **í•œê¸€ ë³´ì¡´**: í•œê¸€ ì§€ë¬¸ì€ ì˜¤íƒ€ ì—†ì´ ê·¸ëŒ€ë¡œ ì˜®ê¸°ì„¸ìš”.
    2. **ìˆ˜ì‹ ë³€í™˜**: ëª¨ë“  ìˆ˜ì‹, ê¸°í˜¸, ìˆ«ìëŠ” ì™„ë²½í•œ LaTeX í¬ë§·ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
       - ë¬¸ì¥ ì¤‘ê°„ ìˆ˜ì‹: $ ... $ ì‚¬ìš©
       - ë…ë¦½ëœ ìˆ˜ì‹: $$ ... $$ ì‚¬ìš©
    3. **êµ¬ì¡° ìœ ì§€**: ë¬¸ì œ ë²ˆí˜¸, ë³´ê¸°(â‘ , â‘¡...), ë°•ìŠ¤ ë“± ë¬¸ì œì§‘ì˜ êµ¬ì¡°ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ìœ ì§€í•˜ì„¸ìš”.
    4. **ê·¸ë¦¼ ì²˜ë¦¬**: ê·¸ë˜í”„ë‚˜ ë„í˜•ì´ ìˆëŠ” ê³³ì€ [ê·¸ë¦¼: ì„¤ëª…]ê³¼ ê°™ì´ ìœ„ì¹˜ë§Œ í‘œì‹œí•˜ì„¸ìš”.
    5. **í’€ì´ ê¸ˆì§€**: ë¬¸ì œë¥¼ í’€ì§€ ë§ê³ , **ì í˜€ìˆëŠ” ê·¸ëŒ€ë¡œ** í…ìŠ¤íŠ¸ë¡œ ì˜®ê¸°ê¸°ë§Œ í•˜ì„¸ìš”.
    6. **ë‹¨ êµ¬ë¶„ í‘œì‹œ**: ì™¼ìª½ ë‹¨ê³¼ ì˜¤ë¥¸ìª½ ë‹¨ ì‚¬ì´ì— "---"ë¥¼ ë„£ì–´ êµ¬ë¶„í•˜ì„¸ìš”.
    """
    
    total_pages = len(pages)
    
    for i, page in enumerate(pages):
        if progress_callback:
            progress_callback(i + 1, total_pages, "ë³€í™˜")
        
        try:
            img_byte_arr = io.BytesIO()
            page.save(img_byte_arr, format='PNG')
            img_bytes = img_byte_arr.getvalue()
            
            image_part = types.Part.from_bytes(
                data=img_bytes,
                mime_type='image/png'
            )
            
            response = client.models.generate_content(
                model='gemini-2.5-flash-lite',
                contents=[prompt, image_part]
            )
            
            full_text += f"\n\n--- Page {i+1} ---\n\n" + response.text
            time.sleep(2)
            
        except Exception as e:
            full_text += f"\n\n--- Page {i+1} (Error: {e}) ---\n\n"
    
    return full_text, None

# ==========================================
# [Markdown ê²€í†  í•¨ìˆ˜]
# ==========================================
def split_into_sections(content):
    """ë¬¸ì œ ë‹¨ìœ„ë¡œ ë¶„ë¦¬"""
    sections = re.split(r'\n(?=---\s*Page|\n---\n|\d+\.\s)', content)
    return [s.strip() for s in sections if s.strip()]

def review_single_section(client, section_text, section_num):
    """ë‹¨ì¼ ì„¹ì…˜ ê²€í† """

    # ê·œì¹™ ê¸°ë°˜(Deterministic) ì¡°ì‚¬ ê²€ì¶œ: LLMì´ ë†“ì¹˜ê¸° ì‰¬ìš´ 'ìˆ˜ì‹/ìˆ«ì/ê´„í˜¸ ë’¤ ì¡°ì‚¬'ë¥¼ 1ì°¨ë¡œ ì¡ìŠµë‹ˆë‹¤.
    rule_errors = rule_check_josa(section_text)
    
    prompt = f"""
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ê³ ë“±í•™êµ ìˆ˜í•™ êµì¬ ì „ë¬¸ êµì •ìì…ë‹ˆë‹¤.
ì•„ë˜ í…ìŠ¤íŠ¸ì—ì„œ ì˜¤ë¥˜ë¥¼ ì°¾ì•„ ë³´ê³ í•´ì£¼ì„¸ìš”.

[ê²€í†  ê¸°ì¤€]
{REVIEW_CRITERIA}

[ì¡°ì‚¬ íŒë‹¨ ê·œì¹™(ë§¤ìš° ì¤‘ìš”)]
1) **ìˆ«ì(ì•„ë¼ë¹„ì•„ ìˆ«ì)ëŠ” í•œììŒìœ¼ë¡œ ì½ìŠµë‹ˆë‹¤.** ì˜ˆ: 1[ì¼], 2[ì´], 3[ì‚¼].
   - ë”°ë¼ì„œ '3ë¥¼'ì€ [ì‚¼] + ëª©ì ê²© ì¡°ì‚¬ì´ë¯€ë¡œ '3ì„'ì´ ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.
2) **ìˆ˜ì‹(LaTeX)ì€ ë§ˆì§€ë§‰ìœ¼ë¡œ ë°œìŒë˜ëŠ” ìš”ì†Œ**(ìˆ«ì/ë³€ìˆ˜/ì²¨ì ë“±)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°›ì¹¨ì„ íŒë‹¨í•´ ì¡°ì‚¬ë¥¼ ê³ ë¥´ì„¸ìš”.
   - ì˜ˆ: $a_1$ ì€ [ì—ì´ ì¼]ë¡œ ì½ìœ¼ë¯€ë¡œ 'ì€'ì´ ìì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.
3) **ê´„í˜¸(...)ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì½ì§€ ì•ŠìŠµë‹ˆë‹¤.** ë‹¤ë§Œ ê²½ìš°ì— ë”°ë¼ ê´„í˜¸ ì•ˆì„ ì½ëŠ” ê²ƒìœ¼ë¡œ ë³´ê³  ì¡°ì‚¬ ì„ íƒì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
   - [ë¬¸ì œ] ê´„í˜¸ ì•ˆ ìˆ˜ì‹/ê¸°í˜¸ë„ ì½ìŠµë‹ˆë‹¤.
   - [í•´ì„¤] êµì¬ ë‚´ë¶€ ì°¸ì¡°/ê°ì£¼(ì˜ˆ: 218p, 10ìª½, í‰ìˆ˜ëŠ¥ ë“±)ëŠ” ì½ì§€ ì•ŠìŠµë‹ˆë‹¤.
   - [í•´ì„¤] ì¡°ê±´/ì •ì˜(ì˜ˆ: x>0, x=0, f(x)=0 ë“±)ë¥¼ ì œì‹œí•˜ëŠ” ê´„í˜¸ëŠ” ì½ê³ , ë‹¨ìˆœ ë¶€ì—° ì„¤ëª…(ì˜ˆ: ì˜ë¯¸(í‰í–‰ì´ë™), ë“±í˜¸(=0))ì€ ì½ì§€ ì•ŠìŠµë‹ˆë‹¤.

[ì…ë ¥ í…ìŠ¤íŠ¸]
{section_text}

[ì¶œë ¥ í˜•ì‹]
ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ JSON ë°°ì—´ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ì˜¤ë¥˜ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ []ì„ ì¶œë ¥í•˜ì„¸ìš”.
ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.

[
    {{
        "original": "ë¬¸ì œê°€ ìˆëŠ” ë¶€ë¶„",
        "corrected": "ìˆ˜ì • ì œì•ˆ",
        "reason": "ìˆ˜ì • ì´ìœ  (ê¸°ì¤€ ë²ˆí˜¸ í¬í•¨)",
        "severity": "high/medium/low"
    }}
]
"""
    
    try:
        response = client.models.generate_content(
            model='gemini-2.5-flash-lite',
            contents=prompt
        )
        
        json_str = response.text.strip()
        json_str = re.sub(r'^```json\s*', '', json_str)
        json_str = re.sub(r'\s*```$', '', json_str)
        
        llm_errors = json.loads(json_str)
        merged = _dedup_errors(rule_errors + (llm_errors or []))
        return {"section": section_num, "errors": merged}
        
    except json.JSONDecodeError:
        # LLM ì¶œë ¥ì´ JSONì´ ì•„ë‹ˆì–´ë„, ê·œì¹™ ê¸°ë°˜ ê²€ì¶œ ê²°ê³¼ëŠ” ë³´ê³ ì„œì— ë‚¨ê¹ë‹ˆë‹¤.
        return {"section": section_num, "errors": rule_errors, "parse_error": response.text}
    except Exception as e:
        return {"section": section_num, "errors": rule_errors, "api_error": str(e)}
def review_markdown(client, content, progress_callback=None):
    """Markdown í…ìŠ¤íŠ¸ ê²€í† """
    
    sections = split_into_sections(content)
    total_sections = len(sections)
    
    all_results = []
    for i, section in enumerate(sections):
        if progress_callback:
            progress_callback(i + 1, total_sections, "ê²€í† ")
        
        result = review_single_section(client, section, i + 1)
        all_results.append(result)
        time.sleep(2)
    
    return all_results

def generate_report(results):
    """ê²€í†  ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
    
    report_lines = ["# ğŸ“ ê²€í†  ë³´ê³ ì„œ\n"]
    total_errors = 0
    high_count = 0
    medium_count = 0
    low_count = 0
    
    for result in results:
        section_num = result["section"]
        errors = result.get("errors", [])
        
        section_header_written = False

        # LLM ì¶œë ¥ íŒŒì‹±/í˜¸ì¶œì— ë¬¸ì œê°€ ìˆì–´ë„, ê·œì¹™ ê¸°ë°˜(rule_check_josa) ê²°ê³¼ëŠ” ë³´ê³ ì„œì— ë‚¨ê¹ë‹ˆë‹¤.
        if "parse_error" in result or "api_error" in result:
            report_lines.append(f"\n## ì„¹ì…˜ {section_num}\n")
            section_header_written = True
            if "parse_error" in result:
                report_lines.append("âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ (LLM ê²°ê³¼ëŠ” ë°˜ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤)\n")
            if "api_error" in result:
                report_lines.append(f"âš ï¸ API ì˜¤ë¥˜: {result['api_error']} (LLM ê²°ê³¼ëŠ” ë°˜ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤)\n")

        if errors:
            if not section_header_written:
                report_lines.append(f"\n## ì„¹ì…˜ {section_num}\n")
            for err in errors:
                total_errors += 1
                severity = err.get("severity", "medium")
                
                if severity == "high":
                    high_count += 1
                    icon = "ğŸ”´"
                elif severity == "medium":
                    medium_count += 1
                    icon = "ğŸŸ¡"
                else:
                    low_count += 1
                    icon = "ğŸŸ¢"
                
                report_lines.append(f"### {icon} ì˜¤ë¥˜ {total_errors}\n")
                report_lines.append(f"- **ì›ë¬¸**: {err.get('original', 'N/A')}\n")
                report_lines.append(f"- **ìˆ˜ì •**: {err.get('corrected', 'N/A')}\n")
                report_lines.append(f"- **ì´ìœ **: {err.get('reason', 'N/A')}\n")
                report_lines.append("")
    
    summary = f"""
## ğŸ“Š ìš”ì•½

| êµ¬ë¶„ | ê°œìˆ˜ |
|------|------|
| ğŸ”´ ë†’ìŒ | {high_count} |
| ğŸŸ¡ ë³´í†µ | {medium_count} |
| ğŸŸ¢ ë‚®ìŒ | {low_count} |
| **ì´ê³„** | **{total_errors}** |

---
"""
    report_lines.insert(1, summary)
    
    return '\n'.join(report_lines), total_errors

# ==========================================
# [ë©”ì¸ UI]
# ==========================================
st.set_page_config(page_title="ìˆ˜í•™ êµì¬ PDF ë³€í™˜ & ê²€í† ", layout="wide")

st.title("PDF ê²€í†  ìë™í™”")
st.markdown("pdfë¥¼ ì—…ë¡œë“œí•˜ë©´ md í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³ , ë¬¸ë²•/ìˆ˜í•™ì  ì˜¤ë¥˜ë¥¼ ê²€í† í•©ë‹ˆë‹¤.")
st.markdown("âš ï¸Integrate ê³„ì •ìœ¼ë¡œ google AI Studioì— ì ‘ì†í•´ ë°œê¸‰ë°›ì€ API Keyë¥¼ ì™¼ìª½ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    api_key = st.text_input("Google API Key", value=DEFAULT_API_KEY, type="password")
    st.caption("[API í‚¤ ë°œê¸‰ë°›ê¸°](https://aistudio.google.com/apikey)")
    
    st.divider()
    
    st.subheader("ì‘ì—… ì„ íƒ")
    do_convert = st.checkbox("1ë‹¨ê³„: PDF â†’ Markdown ë³€í™˜", value=True)
    do_review = st.checkbox("2ë‹¨ê³„: Markdown ê²€í† ", value=True)
    
    st.divider()
    st.info("ë‘ ë‹¨ê³„ë¥¼ ëª¨ë‘ ì„ íƒí•˜ë©´ ë³€í™˜ í›„ ìë™ìœ¼ë¡œ ê²€í† ê°€ ì§„í–‰ë©ë‹ˆë‹¤.")

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜ ì„ íƒí•˜ì„¸ìš”", type=["pdf"])

if uploaded_file is not None:
    # íŒŒì¼ëª… ìë™ ìƒì„±
    original_filename = uploaded_file.name
    file_name_only = os.path.splitext(original_filename)[0]
    convert_filename = f"convert_{file_name_only}.md"
    report_filename = f"report_{file_name_only}.md"
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.write(f"ğŸ“‚ ì…ë ¥: **{original_filename}**")
    with col2:
        st.write(f"ğŸ“„ ë³€í™˜ ê²°ê³¼: **{convert_filename}**")
    with col3:
        st.write(f"ğŸ“‹ ê²€í†  ë³´ê³ ì„œ: **{report_filename}**")
    
    if st.button("ğŸš€ ì‹œì‘í•˜ê¸°", type="primary"):
        # API í‚¤ í™•ì¸
        if not api_key:
            st.error("âŒ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()
        
        # í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = genai.Client(api_key=api_key)
        
        # ì§„í–‰ ìƒí™© í‘œì‹œìš©
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        def update_progress(current, total, stage):
            progress_bar.progress(current / total)
            status_text.text(f"[{stage}] {current}/{total} ì²˜ë¦¬ ì¤‘...")
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        
        try:
            converted_text = None
            review_report = None
            
            # 1ë‹¨ê³„: PDF â†’ Markdown ë³€í™˜
            if do_convert:
                st.subheader("ğŸ“„ 1ë‹¨ê³„: PDF â†’ Markdown ë³€í™˜")
                converted_text, error = process_pdf(client, tmp_path, update_progress)
                
                if error:
                    st.error(error)
                    st.stop()
                
                st.text_area("ë³€í™˜ ê²°ê³¼", converted_text, height=300)
                st.download_button(
                    label="ğŸ“¥ ë³€í™˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
                    data=converted_text,
                    file_name=convert_filename,
                    mime="text/markdown"
                )
                st.success("âœ… ë³€í™˜ ì™„ë£Œ!")
            
            # 2ë‹¨ê³„: Markdown ê²€í† 
            if do_review and converted_text:
                st.subheader("ğŸ“‹ 2ë‹¨ê³„: Markdown ê²€í† ")
                status_text.text("ê²€í† ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
                
                review_results = review_markdown(client, converted_text, update_progress)
                review_report, error_count = generate_report(review_results)
                
                st.text_area("ê²€í†  ë³´ê³ ì„œ", review_report, height=300)
                st.download_button(
                    label="ğŸ“¥ ê²€í†  ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                    data=review_report,
                    file_name=report_filename,
                    mime="text/markdown"
                )
                st.success(f"âœ… ê²€í†  ì™„ë£Œ! ì´ {error_count}ê°œ ì˜¤ë¥˜ ë°œê²¬")
            
            status_text.text("âœ… ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            progress_bar.progress(100)
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(tmp_path):
                os.remove(tmp_path)

else:
    st.info("ğŸ‘† PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

