import streamlit as st
import os
import io
import tempfile
import time
import json
import re
import zipfile
import google.generativeai as genai
from pdf2image import convert_from_path

# ==========================================
# [ì´ˆê¸° ì„¤ì •]
# ==========================================
st.set_page_config(page_title="ì—…ë¬´ ìë™í™”", layout="wide")

# ==========================================
# [CSS ìŠ¤íƒ€ì¼: ì½”ë“œ ë¸”ë¡ ìŠ¤í¬ë¡¤ ì œì–´ ë° ìë™ ì¤„ë°”ê¿ˆ]
# ==========================================
st.markdown("""
    <style>
    /* 1. ë·°ì–´(st.code) ìŠ¤íƒ€ì¼ */
    [data-testid="stCodeBlock"] pre {
        white-space: pre-wrap !important;
        word-break: break-all !important;
        overflow-wrap: break-word !important;
        max-height: 400px !important; /* ê°œë³„ ë¬¸í•­ ë°•ìŠ¤ ë†’ì´ ì œí•œ */
        overflow-y: auto !important;
        overflow-x: hidden !important;
    }
    
    [data-testid="stCodeBlock"] code {
        white-space: pre-wrap !important;
        word-break: break-all !important;
    }
    
    /* 2. ì—ë””í„°(st.text_area) ìŠ¤íƒ€ì¼ */
    .stTextArea textarea {
        font-family: 'Courier New', Courier, monospace !important;
        font-size: 14px !important;
        line-height: 1.5 !important;
    }

    /* 3. ë²„íŠ¼ ë ˆì´ì•„ì›ƒ ì •ë ¬ */
    div[data-testid="column"] {
        display: flex;
        align-items: center; 
    }
    </style>
""", unsafe_allow_html=True)

# ==========================================
# [ìƒìˆ˜ ë° í™˜ê²½ ì„¤ì •]
# ==========================================
DEFAULT_API_KEY = ""

if os.name == 'nt':
    POPPLER_PATH = r"C:\Users\inter\Desktop\Review\poppler-25.12.0\Library\bin"
else:
    POPPLER_PATH = None

# ==========================================
# [í”„ë¡¬í”„íŠ¸]
# ==========================================
PROMPT_FOR_TEX = """
# ğŸ† ì¢…í•© í•™ìˆ  ê°ì‚¬ê´€ (Scholarly Auditor v8.2)

## 1. ì—­í• 
ê³ ë“± ìˆ˜í•™ êµìœ¡ ì½˜í…ì¸ ì˜ **ìµœì¢… ê²€ì¦ì**ë¡œì„œ, ì˜¤ë¥˜ë¥¼ ì°¾ì•„ë‚´ì–´ **ê¹”ë”í•œ í‘œ(Table)**ë¡œ ë³´ê³ í•©ë‹ˆë‹¤.

## 2. ì¶œë ¥ í˜•ì‹ (ì—„ìˆ˜)
ì„œìˆ í˜• ì¤„ê¸€ì„ ì ˆëŒ€ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤ì§ **ì•„ë˜ì˜ í‘œ í˜•ì‹**ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
ì˜¤ë¥˜ê°€ ì—†ë‹¤ë©´ í‘œë¥¼ ì¶œë ¥í•˜ì§€ ë§ê³  "âœ… **ë°œê²¬ëœ ì˜¤ë¥˜ ì—†ìŒ**"ì´ë¼ê³ ë§Œ ì“°ì‹­ì‹œì˜¤.

### [Table A: í•™ìˆ  ê°ì‚¬ ë³´ê³ ì„œ] (ì¹˜ëª…ì  ì˜¤ë¥˜)
* **ê¸°ì¤€:** ìˆ˜í•™ì  ì§„ë¦¬ê°’, ì •ë‹µ, ë¶€í˜¸, ê°œë… ì˜¤ë¥˜ (í™•ì‹ ë„ 100%)
| ìœ„ì¹˜ | ì˜¤ë¥˜ ë‚´ìš© | ì›ë¬¸ $\\to$ ìˆ˜ì • ì œì•ˆ | ê·¼ê±° ë° ì˜ê²¬ |
| :--- | :--- | :--- | :--- |
| (ì˜ˆ: í•´ì„¤ 3í–‰) | (ì˜ˆ: ë¶€í˜¸ ì˜¤ë¥˜) | **[ì›ë¬¸]** $f(t)$ <br> $\\downarrow$ <br> **[ìˆ˜ì •]** $f(-t)$ | yì¶• ëŒ€ì¹­ì´ë¯€ë¡œ -t ëŒ€ì… í•„ìš” |

### [Table B: ë³€í™˜ ì˜¤ë¥˜ í´ë¦°ì—…] (ë‹¨ìˆœ ìˆ˜ì •)
* **ê¸°ì¤€:** ë„ì–´ì“°ê¸°, ì˜¤íƒ€, ë¬¸ë²•, ë‹¨ìˆœ í¸ì§‘
| ìœ„ì¹˜ | ì˜¤ë¥˜ ë‚´ìš© | ì›ë¬¸ $\\to$ ìˆ˜ì • ì œì•ˆ |
| :--- | :--- | :--- |
| (ì˜ˆ: ë¬¸ì œ 1í–‰) | (ì˜ˆ: ë„ì–´ì“°ê¸°) | 3 ê°œë¥¼ $\\to$ 3ê°œë¥¼ |

### [Table C: ê°œì„  ì œì•ˆ] (ê¶Œì¥ ì‚¬í•­)
* **ê¸°ì¤€:** ë” ë‚˜ì€ í’€ì´, ê°€ë…ì„±, êµìœ¡ì  ì œì•ˆ
| ìœ„ì¹˜ | ì œì•ˆ ìœ í˜• | ë‚´ìš© ë° ì˜ê²¬ |
| :--- | :--- | :--- |
| (ì˜ˆ: ì‹ (ë‚˜)) | (ì˜ˆ: í’€ì´ ê°œì„ ) | ë¡œí”¼íƒˆ ì •ë¦¬ë³´ë‹¤ ë¯¸ë¶„ê³„ìˆ˜ ì •ì˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. |

## 3. ì£¼ì˜ ì‚¬í•­
1. ê° í‘œì˜ í—¤ë”(Table A, B, C)ëŠ” ì˜¤ë¥˜ê°€ ìˆì„ ë•Œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
2. ìˆ˜ì‹ì€ LaTeX ë¬¸ë²•($$)ì„ ìœ ì§€í•˜ì„¸ìš”.
"""

PROMPT_FOR_PDF = """
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ê³ ë“±í•™êµ ìˆ˜í•™ êµì¬ ì „ë¬¸ êµì •ìì…ë‹ˆë‹¤.
ì•„ë˜ í…ìŠ¤íŠ¸ì—ì„œ ì˜¤ë¥˜ë¥¼ ì°¾ì•„ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
(ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ìƒëµ...)
[
    {{
        "original": "ë¬¸ì œê°€ ìˆëŠ” ë¶€ë¶„",
        "corrected": "ìˆ˜ì • ì œì•ˆ",
        "reason": "ìˆ˜ì • ì´ìœ ",
        "severity": "high/medium/low"
    }}
]
"""

# ==========================================
# [ê³µí†µ ìœ í‹¸ë¦¬í‹°]
# ==========================================
_JONGSUNG_LIST = ["", "ã„±", "ã„²", "ã„³", "ã„´", "ã„µ", "ã„¶", "ã„·", "ã„¹", "ã„º", "ã„»", "ã„¼", "ã„½", "ã„¾", "ã„¿", "ã…€", "ã…", "ã…‚", "ã…„", "ã……", "ã…†", "ã…‡", "ã…ˆ", "ã…Š", "ã…‹", "ã…Œ", "ã…", "ã…"]
_LATIN_LAST_JONG = {"A": "", "B": "", "C": "", "D": "", "E": "", "F": "", "G": "", "H": "", "I": "", "J": "", "K": "", "L": "ã„¹", "M": "ã…", "N": "ã„´", "O": "", "P": "", "Q": "", "R": "ã„¹", "S": "", "T": "", "U": "", "V": "", "W": "", "X": "", "Y": "", "Z": ""}
_DIGIT_LAST_JONG = {"0": "ã…‡", "1": "ã„¹", "2": "", "3": "ã…", "4": "", "5": "", "6": "ã„±", "7": "ã„¹", "8": "ã„¹", "9": ""}
_MATH_JOSA_PATTERN = re.compile(r'(?P<math>\${1,2}[^$]+?\${1,2})(?P<ws>\s*)(?P<josa>ìœ¼ë¡œ|ë¡œ|ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ê³¼|ì™€)(?=[\s\.,;:\)\]\}\!?]|$)')
_NUM_JOSA_PATTERN = re.compile(r'(?P<num>\d[\d,]*(?:\.\d+)?)(?P<ws>\s*)(?P<josa>ìœ¼ë¡œ|ë¡œ|ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ê³¼|ì™€)(?=[\s\.,;:\)\]\}\!?]|$)')

def _hangul_last_jong(text):
    if not text: return ""
    s = re.sub(r'[\s\.,;:!\?\)\]\}]+$', '', text.strip())
    for ch in reversed(s):
        code = ord(ch)
        if 0xAC00 <= code <= 0xD7A3: return _JONGSUNG_LIST[(code - 0xAC00) % 28]
    return ""
def _number_last_jong(num_raw):
    if not num_raw: return ""
    s = num_raw.strip().replace(",", "").replace(" ", "").lstrip("+")
    if s.startswith("-"): s = s[1:]
    if "." in s: return _DIGIT_LAST_JONG.get(s.split(".")[1][-1], "") if s.split(".")[1] else ""
    digits = re.sub(r"\D", "", s).lstrip("0") or "0"
    if digits == "0": return "ã…‡"
    return _DIGIT_LAST_JONG.get(digits[-1])
def _latin_last_jong(text):
    s = text.strip()
    if not s: return ""
    for ch in reversed(s):
        if ch.isalpha(): return _LATIN_LAST_JONG.get(ch.upper(), "")
    return ""
def _expected_josa(josa, last_jong):
    has = (last_jong != "")
    if josa in ("ì€", "ëŠ”"): return "ì€" if has else "ëŠ”"
    if josa in ("ì´", "ê°€"): return "ì´" if has else "ê°€"
    if josa in ("ì„", "ë¥¼"): return "ì„" if has else "ë¥¼"
    if josa in ("ê³¼", "ì™€"): return "ê³¼" if has else "ì™€"
    if josa in ("ìœ¼ë¡œ", "ë¡œ"): return "ë¡œ" if (not has or last_jong == "ã„¹") else "ìœ¼ë¡œ"
    return josa
def _last_jong_from_math(math): return "" 
def get_line_number(full_text, index): return full_text.count('\n', 0, index) + 1

def rule_check_josa(section_text):
    errors = []
    for m in _MATH_JOSA_PATTERN.finditer(section_text):
        math = m.group("math")
        ws = m.group("ws") or ""
        josa = m.group("josa")
        last_jong = _last_jong_from_math(math) 
        math_content = math.strip("$")
        last_char = math_content[-1] if math_content else ""
        if re.match(r'\d', last_char): derived_jong = _number_last_jong(last_char)
        elif re.match(r'[A-Za-z]', last_char): derived_jong = _latin_last_jong(last_char)
        else: derived_jong = "" 
        exp = _expected_josa(josa, derived_jong)
        original = f"{math}{ws}{josa}"
        corrected = f"{math}{exp}"
        line_num = get_line_number(section_text, m.start())
        if josa != exp and derived_jong != "":
            errors.append({"location": f"{line_num}í–‰", "original": original, "corrected": corrected, "reason": "ì¡°ì‚¬ ì˜¤ë¥˜(ìˆ˜ì‹)", "severity": "medium"})
    for m in _NUM_JOSA_PATTERN.finditer(section_text):
        num = m.group("num")
        ws = m.group("ws") or ""
        josa = m.group("josa")
        if m.start() > 0 and section_text[m.start() - 1] == "$": continue
        last_jong = _number_last_jong(num)
        exp = _expected_josa(josa, last_jong)
        original = f"{num}{ws}{josa}"
        corrected = f"{num}{exp}"
        line_num = get_line_number(section_text, m.start())
        if josa != exp or ws:
            errors.append({"location": f"{line_num}í–‰", "original": original, "corrected": corrected, "reason": "ì¡°ì‚¬ ì˜¤ë¥˜(ìˆ«ì)", "severity": "medium"})
    return errors

def _dedup_errors(errors):
    seen = set(); out = []
    for e in errors:
        key = (e.get("original",""), e.get("corrected",""), e.get("reason",""))
        if key in seen: continue
        seen.add(key); out.append(e)
    return out

# ==========================================
# [ë¡œì§ A] LaTeX ZIP ì²˜ë¦¬ (ë©”ì¸ìš©)
# ==========================================
def extract_tex_from_zip(zip_file_bytes):
    try:
        with zipfile.ZipFile(zip_file_bytes) as z:
            tex_files = [f for f in z.namelist() if f.lower().endswith('.tex')]
            if not tex_files: return None, "ZIP íŒŒì¼ ë‚´ì— .tex íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."
            target_file = tex_files[0]
            try: content = z.read(target_file).decode('utf-8')
            except UnicodeDecodeError: content = z.read(target_file).decode('cp949')
            return content, None
    except Exception as e: return None, f"ZIP ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"

# [ë©”ì¸ í˜ì´ì§€ìš© êµ¬í˜• íŒŒì„œ - ìœ ì§€]
def parse_tex_content(tex_content):
    pattern = r'\\begin\{document\}([\s\S]*?)\\end\{document\}'
    match = re.search(pattern, tex_content)
    body = match.group(1).strip() if match else tex_content
    body = re.sub(r'\\maketitle', '', body)
    body = re.sub(r'\\newpage', '', body)
    body = re.sub(r'\\clearpage', '', body)
    start_pattern = re.compile(r'\\section\*?\{')
    matches = list(start_pattern.finditer(body))
    if not matches: return [body]
    chunks = []
    for i in range(len(matches)):
        start_idx = matches[i].start()
        end_idx = matches[i+1].start() if i + 1 < len(matches) else len(body)
        chunks.append(body[start_idx:end_idx])
    final_items = []
    current_item_text = ""
    explanation_keywords = ["í•´ë²•", "í•´ì„¤", "í’€ì´", "ì •ë‹µ", "Solution", "ì„±ì§ˆ", "ê°œë…", "ì •ë¦¬", "ë¶„ì„", "ì ‘ê·¼", "Note", "Tip", "Guide", "ê³µì‹"]
    ignore_keywords = ["Day", "ì¼ì°¨"] 
    for chunk in chunks:
        brace_open_index = chunk.find('{')
        title_content = ""
        if brace_open_index != -1:
            brace_count = 1
            for k, char in enumerate(chunk[brace_open_index+1:], 1):
                if char == '{': brace_count += 1
                elif char == '}': brace_count -= 1
                if brace_count == 0:
                    title_content = chunk[brace_open_index+1 : brace_open_index+k]
                    break
        is_ignore = any(kw in title_content for kw in ignore_keywords)
        is_explicit_explanation = any(kw in title_content for kw in explanation_keywords)
        has_korean_text = bool(re.search(r'[ê°€-í£]', title_content))
        is_explanation = is_explicit_explanation or (has_korean_text and not is_ignore)
        if is_ignore:
            if current_item_text.strip(): final_items.append(current_item_text.strip())
            current_item_text = ""
            continue
        if is_explanation:
            if current_item_text: current_item_text += "\n" + chunk
            else:
                if final_items: final_items[-1] += "\n" + chunk
                else: current_item_text = chunk
        else:
            if current_item_text.strip(): final_items.append(current_item_text.strip())
            current_item_text = chunk
    if current_item_text.strip(): final_items.append(current_item_text.strip())
    return final_items

# ==========================================
# [NEW] ê°œë°œìš© íŒŒì„œ (ë¬¸í•­ ë²ˆí˜¸ ê¸°ì¤€ ì—„ê²© ë¶„ë¦¬)
# ==========================================
def parse_tex_content_dev(tex_content):
    """
    [ê°œë°œìš©] TeX ë‚´ìš©ì„ ì¤„ ë‹¨ìœ„ë¡œ ì½ì–´ (ë¬¸í•­ + ëª¨ë“  í•´ì„¤) ì„¸íŠ¸ë¡œ ë¶„ë¦¬.
    ì˜¤ì§ 'ë¬¸í•­ ë²ˆí˜¸'ê°€ ë‚˜ì˜¬ ë•Œë§Œ ì„¸íŠ¸ë¥¼ ëŠìŠµë‹ˆë‹¤.
    """
    # 1. ë¬¸ì„œ ë³¸ë¬¸ ì¶”ì¶œ
    pattern = r'\\begin\{document\}([\s\S]*?)\\end\{document\}'
    match = re.search(pattern, tex_content)
    body = match.group(1).strip() if match else tex_content

    # 2. ë¶ˆí•„ìš”í•œ LaTeX ëª…ë ¹ì–´ ì œê±°
    body = re.sub(r'\\maketitle', '', body)
    body = re.sub(r'\\newpage', '', body)
    body = re.sub(r'\\clearpage', '', body)
    
    # 3. ì¤„ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    lines = [line.strip() for line in body.split('\n') if line.strip()]
    
    items = []
    current_item_lines = []
    current_item_label = "ì„œë¬¸/ê³µí†µ" 
    
    # [ì •ê·œì‹ ì •ì˜]
    # 1. ìˆœìˆ˜ ìˆ«ì (ì˜ˆ: "28", "29.")
    regex_pure_num = re.compile(r'^\d+(\.\s*)?$')
    # 2. ì„¹ì…˜ ë‚´ì˜ ìˆ«ì (ì˜ˆ: \section*{28}, \section*{110 \\ 29})
    # ì£¼ì˜: \section*{í•´ë²•} ê°™ì€ ê±´ ì¡íˆë©´ ì•ˆ ë¨. ì˜¤ì§ ìˆ«ì, ê³µë°±, ì¤„ë°”ê¿ˆ(\\)ë§Œ í—ˆìš©
    regex_section_num = re.compile(r'^\\section\*?\{\s*(\d+(\s*\\\\)?\s*)+\}$')
    
    ignore_keywords = ["Day", "ì¼ì°¨"] 

    for line in lines:
        is_ignore = any(kw in line for kw in ignore_keywords)
        if is_ignore: continue

        # --- ë¬¸í•­ ì‹œì‘ íŒë³„ ë¡œì§ ---
        is_question_start = False
        new_label = ""

        if regex_pure_num.match(line):
            is_question_start = True
            new_label = line.replace('.', '').strip()
            
        elif regex_section_num.match(line):
            # ì„¹ì…˜ ë‚´ë¶€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            inner_text = re.sub(r'\\section\*?\{', '', line).rstrip('}')
            # í…ìŠ¤íŠ¸ê°€ ì •ë§ ìˆ«ìë¡œë§Œ(ë˜ëŠ” \\ í¬í•¨) ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            # (ì´ë¯¸ regex_section_numì´ ê±°ë¥´ê¸´ í–ˆì§€ë§Œ ì•ˆì „ì¥ì¹˜)
            if re.fullmatch(r'[\d\s\\]+', inner_text):
                is_question_start = True
                # "110 \\ 29" ê°™ì€ ê²½ìš° ë§ˆì§€ë§‰ ìˆ«ì "29"ë¥¼ ë¼ë²¨ë¡œ ì‚¬ìš©
                new_label = inner_text.split(r'\\')[-1].strip()

        # --- ë¶„ê¸° ì²˜ë¦¬ ---
        if is_question_start:
            # ê¸°ì¡´ì— ëª¨ìœ¼ë˜ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì €ì¥ (ì´ì „ ë¬¸í•­ ì„¸íŠ¸ ì™„ë£Œ)
            if current_item_lines:
                items.append({
                    "label": f"{current_item_label}ë²ˆ ë¬¸í•­",
                    "content": "\n".join(current_item_lines)
                })
                current_item_lines = []
            
            # ìƒˆ ë¬¸í•­ ì‹œì‘
            current_item_label = new_label
            current_item_lines.append(line)
        else:
            # ë¬¸í•­ ë²ˆí˜¸ê°€ ì•„ë‹ˆë©´ (í•´ì„¤, ê°œë…, ì§€ë¬¸ ë“±) ë¬´ì¡°ê±´ í˜„ì¬ ì„¸íŠ¸ì— ì¶”ê°€
            current_item_lines.append(line)

    # ë§ˆì§€ë§‰ ë¬¸í•­ ì €ì¥
    if current_item_lines:
        items.append({
            "label": f"ë¬¸í•­ {current_item_label}",
            "content": "\n".join(current_item_lines)
        })

    # í›„ì²˜ë¦¬: ë‚´ìš©ì´ ë„ˆë¬´ ì§§ì€ í•­ëª© ì œê±° (ì“°ë ˆê¸° ë°ì´í„°)
    valid_items = []
    for item in items:
        if len(item['content']) > 5:
            valid_items.append(item)
            
    return valid_items

# ==========================================
# [ê³µí†µ] ë¦¬ë·° ë° ë¦¬í¬íŠ¸ ìƒì„±
# ==========================================
def review_tex_section(model, section_text, section_num):
    rule_errors = rule_check_josa(section_text)
    prompt = PROMPT_FOR_TEX + "\n\n---------------------------------------------------------\n[ê²€í† í•  í…ìŠ¤íŠ¸]\n" + section_text + "\n---------------------------------------------------------"
    try:
        response = model.generate_content(prompt)
        return {"section": section_num, "rule_errors": rule_errors, "ai_report_text": response.text}
    except Exception as e:
        return {"section": section_num, "rule_errors": rule_errors, "api_error": str(e)}

def generate_report_for_tex(results_grouped_by_file):
    lines = ["# ğŸ† ì¢…í•© í•™ìˆ  ê°ì‚¬ ë³´ê³ ì„œ\n"]
    for filename, results in results_grouped_by_file.items():
        lines.append(f"\n# ğŸ“ íŒŒì¼: {filename}")
        lines.append("---")
        for res in results:
            lines.append(f"\n## ğŸ“„ {res.get('label', 'ë¬¸í•­ ì„¸íŠ¸ ' + str(res['section']))}")
            if res.get('rule_errors'):
                lines.append("### ğŸ [Python ê·œì¹™ ê°ì§€] (ì°¸ê³ ìš©)")
                lines.append("| ìœ„ì¹˜ | ì˜¤ë¥˜ ë‚´ìš© | ì›ë¬¸ $\\to$ ìˆ˜ì • ì œì•ˆ |")
                lines.append("| :--- | :--- | :--- |")
                for err in res['rule_errors']:
                    lines.append(f"| {err['location']} | {err['reason']} | {err['original']} $\\to$ {err['corrected']} |")
                lines.append("\n")
            if 'api_error' in res: 
                lines.append(f"âš ï¸ **API Error:** {res['api_error']}")
            else: 
                lines.append(res['ai_report_text'])
            lines.append("\n---")
    return "\n".join(lines)


# ==========================================
# [ë¡œì§ B] 2512 PDF ì²˜ë¦¬
# ==========================================
def process_pdf(model, pdf_path, progress_callback=None):
    try:
        if POPPLER_PATH: pages = convert_from_path(pdf_path, dpi=300, poppler_path=POPPLER_PATH)
        else: pages = convert_from_path(pdf_path, dpi=300)
    except Exception as e: return None, f"ì˜¤ë¥˜: PDF ë³€í™˜ ì‹¤íŒ¨ ({e})"
    full_text = ""
    prompt = "ì´ë¯¸ì§€ ë‚´ìš©ì„ Markdownìœ¼ë¡œ ë³€í™˜(OCR)í•˜ì„¸ìš”. ìˆ˜ì‹ì€ LaTeX($$)ì‚¬ìš©, í•œê¸€ ë³´ì¡´."
    total_pages = len(pages)
    for i, page in enumerate(pages):
        if progress_callback: progress_callback(i + 1, total_pages, "ë³€í™˜")
        try:
            response = model.generate_content([prompt, page])
            full_text += f"\n\n--- Page {i+1} ---\n\n" + response.text
            time.sleep(2)
        except Exception as e: full_text += f"\n\n--- Page {i+1} (Error: {e}) ---\n\n"
    return full_text, None

def split_pdf_sections(content):
    sections = re.split(r'\n(?=---\s*Page|\n---\n|\d+\.\s)', content)
    return [s.strip() for s in sections if s.strip()]

def review_pdf_section(model, section_text, section_num):
    rule_errors = rule_check_josa(section_text)
    prompt = PROMPT_FOR_PDF.format(section_text=section_text)
    try:
        response = model.generate_content(prompt)
        json_str = response.text.strip().replace('```json', '').replace('```', '')
        llm_errors = json.loads(json_str)
        merged = _dedup_errors(rule_errors + (llm_errors or []))
        return {"section": section_num, "errors": merged}
    except json.JSONDecodeError: return {"section": section_num, "errors": rule_errors, "parse_error": response.text}
    except Exception as e: return {"section": section_num, "errors": rule_errors, "api_error": str(e)}

def generate_report_for_pdf(results):
    report_lines = ["# ğŸ“ ê²€í†  ë³´ê³ ì„œ (2512)\n"]
    total_errors = 0
    for result in results:
        section_num = result["section"]
        errors = result.get("errors", [])
        if "parse_error" in result or "api_error" in result:
            report_lines.append(f"\n## ì„¹ì…˜ {section_num}\nâš ï¸ ì˜¤ë¥˜ ë°œìƒ")
        if errors:
            report_lines.append(f"\n## ì„¹ì…˜ {section_num}\n")
            for err in errors:
                total_errors += 1
                icon = "ğŸ”´" if err.get("severity") == "high" else "ğŸŸ¡"
                report_lines.append(f"### {icon} ì˜¤ë¥˜ {total_errors}")
                report_lines.append(f"- **ì›ë¬¸**: {err.get('original', 'N/A')}")
                report_lines.append(f"- **ìˆ˜ì •**: {err.get('corrected', 'N/A')}")
                report_lines.append(f"- **ì´ìœ **: {err.get('reason', 'N/A')}\n")
    return '\n'.join(report_lines)

# ==========================================
# [í™”ë©´ ì „í™˜ ê´€ë¦¬]
# ==========================================
if 'current_page' not in st.session_state:
    st.session_state.current_page = 'main'

def navigate_to(page):
    st.session_state.current_page = page

# ==========================================
# [í™”ë©´ 1] ë©”ì¸ í˜ì´ì§€ (ìš´ì˜ìš©)
# ==========================================
def main_page():
    col_title, col_btns = st.columns([6, 4])
    with col_title: 
        st.title("ì—…ë¬´ ìë™í™” (LaTeX ZIP)")
    with col_btns:
        c1, c2, c3 = st.columns(3)
        with c1:
            st.link_button("â±ï¸ íƒ€ì´ë¨¸", "https://integrate-git.github.io/timer/timer_c3.html", use_container_width=True)
        with c2:
            if st.button("ğŸ› ï¸ ê°œë°œìš©", use_container_width=True):
                navigate_to('dev')
                st.rerun()
        with c3:
            if st.button("2512ver â–¶", use_container_width=True): 
                navigate_to('2512')
                st.rerun()

    st.markdown("""
    **LaTeX ZIP ìë™ ì •ì œ ë° ê²€í†  ì‹œìŠ¤í…œ**ì…ë‹ˆë‹¤.
    ì—¬ëŸ¬ ê°œì˜ **ZIP íŒŒì¼**ì„ í•œ ë²ˆì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)

    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        if 'api_key' not in st.session_state: st.session_state.api_key = DEFAULT_API_KEY
        api_input = st.text_input("Google API Key", value=st.session_state.api_key, type="password")
        st.session_state.api_key = api_input
    
    uploaded_zips = st.file_uploader("ZIP íŒŒì¼ ì—…ë¡œë“œ (.zip)", type=["zip"], accept_multiple_files=True)
    all_files_data = []

    if uploaded_zips:
        with st.status("íŒŒì¼ ë¶„ì„ ë° ì¶”ì¶œ ì¤‘...", expanded=True) as status:
            for i, uploaded_zip in enumerate(uploaded_zips):
                status.write(f"ğŸ“‚ ë¶„ì„ ì¤‘: {uploaded_zip.name}")
                tex_content, error = extract_tex_from_zip(uploaded_zip)
                if error:
                    st.error(f"{uploaded_zip.name}: {error}")
                    continue
                # ë©”ì¸ í˜ì´ì§€ëŠ” ê¸°ì¡´ íŒŒì„œ ì‚¬ìš© (í†µí•© í…ìŠ¤íŠ¸ ì¶œë ¥)
                items = parse_tex_content(tex_content)
                full_text = "\n\n" + ("="*30) + "\n\n".join(items)
                all_files_data.append({"filename": uploaded_zip.name, "items": items, "full_text": full_text, "index": i})
            status.update(label="ëª¨ë“  íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ!", state="complete", expanded=False)

        if all_files_data:
            st.divider()
            file_options = {f"{data['filename']}": data for data in all_files_data}
            selected_option = st.selectbox("ğŸ“‚ í™•ì¸í•˜ê³  ì‹¶ì€ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”:", list(file_options.keys()))
            
            if selected_option:
                selected_data = file_options[selected_option]
                idx = selected_data['index']
                full_text = selected_data['full_text']
                items = selected_data['items']
                st.info(f"âœ… '{selected_data['filename']}' ë‚´ìš© (ì´ {len(items)}ê°œ ë¬¸í•­ ì„¸íŠ¸)")
                tab1, tab2 = st.tabs(["ğŸ‘ï¸ ë·°ì–´ (Color & Wrap)", "âœï¸ ì—ë””í„° (ìˆ˜ì •)"])
                with tab1: st.code(full_text, language='latex')
                with tab2: st.text_area(f"Editor_{idx}", value=full_text, height=600, label_visibility="collapsed")
            
            st.divider()
            if st.button("ğŸš€ ì „ì²´ íŒŒì¼ AI í•™ìˆ  ê°ì‚¬ ì‹œì‘", type="primary"):
                if not st.session_state.api_key: st.error("API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."); st.stop()
                genai.configure(api_key=st.session_state.api_key)
                model = genai.GenerativeModel('gemini-1.5-flash')
                progress_bar = st.progress(0)
                status_text = st.empty()
                total_tasks = sum(len(f['items']) for f in all_files_data)
                current_task_idx = 0
                results_by_file = {}

                for file_data in all_files_data:
                    filename = file_data['filename']
                    items = file_data['items']
                    file_results = []
                    status_text.text(f"ğŸ“‚ {filename} ê²€í†  ì¤‘...")
                    for j, item_text in enumerate(items):
                        current_task_idx += 1
                        progress_bar.progress(current_task_idx / total_tasks)
                        max_retries = 3; retry_delay = 5
                        for attempt in range(max_retries):
                            result = review_tex_section(model, item_text, j + 1)
                            if "api_error" in result and "429" in str(result["api_error"]):
                                if attempt < max_retries - 1:
                                    time.sleep(retry_delay); retry_delay *= 2
                                    continue
                            file_results.append(result)
                            break
                        time.sleep(2) 
                    results_by_file[filename] = file_results
                
                report = generate_report_for_tex(results_by_file)
                st.divider()
                st.subheader("ğŸ“‹ í†µí•© ê°ì‚¬ ê²°ê³¼ ë³´ê³ ì„œ")
                st.markdown(report)
                st.download_button("ğŸ“¥ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ", report, file_name="integrated_auditor_report.md")
                st.success("ëª¨ë“  íŒŒì¼ì˜ ê²€í† ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

# ==========================================
# [í™”ë©´ 3] ê°œë°œìš© í˜ì´ì§€ (Dev Mode)
# ==========================================
def page_dev():
    if st.button("â† ë©”ì¸ìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        navigate_to('main')
        st.rerun()
    st.divider()
    
    st.title("ğŸ› ï¸ í…ŒìŠ¤íŠ¸ í˜ì´ì§€")
    st.warning("""âš ï¸ ì´ê³³ì€ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ë° ë””ë²„ê¹…ì„ ìœ„í•œ ê³µê°„ì…ë‹ˆë‹¤.  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1. ë¬¸í•­ë³„ ë¶„ë¦¬: ë¬¸í•­ë¼ë¦¬ ë¶„ë¦¬ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬¸í•­ ë²ˆí˜¸ê°€ ë§ëŠ”ì§€ í™•ì¸í•˜ê³ , í•„ìš”í•œ ë¶€ë¶„ë§Œ ë³µì‚¬í•˜ì„¸ìš”.""")

    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì • (Dev)")
        if 'api_key' not in st.session_state: st.session_state.api_key = DEFAULT_API_KEY
        api_input = st.text_input("Google API Key", value=st.session_state.api_key, type="password")
        st.session_state.api_key = api_input
    
    uploaded_zips = st.file_uploader("ZIP íŒŒì¼ ì—…ë¡œë“œ", type=["zip"], accept_multiple_files=True, key="dev_uploader")
    all_files_data = []

    if uploaded_zips:
        with st.status("íŒŒì¼ ë¶„ì„ ë° ì¶”ì¶œ ì¤‘...", expanded=True) as status:
            for i, uploaded_zip in enumerate(uploaded_zips):
                status.write(f"ğŸ“‚ ë¶„ì„ ì¤‘: {uploaded_zip.name}")
                tex_content, error = extract_tex_from_zip(uploaded_zip)
                if error:
                    st.error(f"{uploaded_zip.name}: {error}")
                    continue
                # [Dev] ê°œì„ ëœ íŒŒì„œ ì‚¬ìš© -> itemsëŠ” [{'label': 'ë¬¸í•­ 28', 'content': '...'}, ...] í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
                items = parse_tex_content_dev(tex_content)
                all_files_data.append({"filename": uploaded_zip.name, "items": items, "index": i})
            status.update(label="ëª¨ë“  íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ!", state="complete", expanded=False)

        if all_files_data:
            st.divider()
            file_options = {f"{data['filename']}": data for data in all_files_data}
            selected_option = st.selectbox("ğŸ“‚ í™•ì¸í•˜ê³  ì‹¶ì€ íŒŒì¼ ì´ë¦„ ì„ íƒ", list(file_options.keys()), key="dev_selectbox")
            
            if selected_option:
                selected_data = file_options[selected_option]
                items = selected_data['items'] # ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
                idx = selected_data['index']
                
                st.caption(f"âœ… '{selected_data['filename']}' ë‚´ìš© (ì´ {len(items)}ê°œ ë¬¸í•­ ì„¸íŠ¸)")

                # [ì¤‘ìš”] ë¬¸í•­ë³„ ê°œë³„ ë°•ìŠ¤ ìƒì„± (ë°˜ë³µë¬¸)
                for j, item_data in enumerate(items):
                    item_label = item_data.get('label', f"{j+1}")
                    item_text = item_data.get('content', '')
                    
                    with st.expander(f"{item_label}", expanded=True):
                        # ê° ë¬¸í•­ë§ˆë‹¤ íƒ­ ìƒì„±
                        tab1, tab2 = st.tabs(["ğŸ¦LaTeX", "ğŸ“ë©”ëª¨ì¥st"])
                        with tab1:
                            st.code(item_text, language='latex')
                        with tab2:
                            st.text_area(f"Dev_Edit_{idx}_{j}", value=item_text, height=300, label_visibility="collapsed")
                    
                    st.divider()

            st.divider()
            if st.button("ğŸš€ (Dev) AI ê°ì‚¬ ì‹œì‘", type="primary"):
                if not st.session_state.api_key: st.error("API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."); st.stop()
                genai.configure(api_key=st.session_state.api_key)
                model = genai.GenerativeModel('gemini-1.5-flash')
                progress_bar = st.progress(0)
                status_text = st.empty()
                total_tasks = sum(len(f['items']) for f in all_files_data)
                current_task_idx = 0
                results_by_file = {}

                for file_data in all_files_data:
                    filename = file_data['filename']
                    items = file_data['items']
                    file_results = []
                    status_text.text(f"ğŸ“‚ {filename} ê²€í†  ì¤‘...")
                    for j, item_data in enumerate(items):
                        item_text = item_data.get('content', '')
                        item_label = item_data.get('label', f"ë¬¸í•­ {j+1}")
                        
                        current_task_idx += 1
                        progress_bar.progress(current_task_idx / total_tasks)
                        max_retries = 3; retry_delay = 5
                        for attempt in range(max_retries):
                            # labelë„ ë„˜ê²¨ì£¼ë©´ ì¢‹ê² ì§€ë§Œ review í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ìœ ì§€ ìœ„í•´
                            result = review_tex_section(model, item_text, j + 1)
                            # ê²°ê³¼ì— ë¼ë²¨ ì¶”ê°€
                            result['label'] = item_label 
                            
                            if "api_error" in result and "429" in str(result["api_error"]):
                                if attempt < max_retries - 1:
                                    time.sleep(retry_delay); retry_delay *= 2
                                    continue
                            file_results.append(result)
                            break
                        time.sleep(2) 
                    results_by_file[filename] = file_results
                
                report = generate_report_for_tex(results_by_file)
                st.divider()
                st.subheader("ğŸ“‹ í†µí•© ê°ì‚¬ ê²°ê³¼ ë³´ê³ ì„œ (Dev)")
                st.markdown(report)
                st.download_button("ğŸ“¥ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ", report, file_name="dev_report.md")
                st.success("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

# ==========================================
# [í™”ë©´ 2] 2512 í˜ì´ì§€ (Legacy PDF)
# ==========================================
def page_2512():
    if st.button("â† ë©”ì¸ìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
        navigate_to('main')
        st.rerun()
    st.divider()
    st.title("ìˆ˜í•™ êµì¬ PDF ë³€í™˜ & ê²€í†  (2512)")

    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì • (2512)")
        if 'api_key' not in st.session_state: st.session_state.api_key = DEFAULT_API_KEY
        api_input = st.text_input("Google API Key", value=st.session_state.api_key, type="password")
        st.session_state.api_key = api_input
        st.divider()
        do_convert = st.checkbox("1ë‹¨ê³„: PDF â†’ Markdown ë³€í™˜", value=True)
        do_review = st.checkbox("2ë‹¨ê³„: Markdown ê²€í† ", value=True)

    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜ ì„ íƒí•˜ì„¸ìš”", type=["pdf"])

    if uploaded_file is not None:
        if st.button("ğŸš€ ì‹œì‘í•˜ê¸°", type="primary"):
            if not st.session_state.api_key: st.error("âŒ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."); st.stop()
            
            genai.configure(api_key=st.session_state.api_key)
            model = genai.GenerativeModel('gemini-1.5-flash')

            progress_bar = st.progress(0)
            status_text = st.empty()
            
            def update_progress(current, total, stage):
                progress_bar.progress(current / total)
                status_text.text(f"[{stage}] {current}/{total} ì²˜ë¦¬ ì¤‘...")
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_path = tmp_file.name
            
            try:
                converted_text = None
                if do_convert:
                    st.subheader("ğŸ“„ 1ë‹¨ê³„: PDF â†’ Markdown ë³€í™˜")
                    converted_text, error = process_pdf(model, tmp_path, update_progress)
                    if error: st.error(error); st.stop()
                    st.text_area("ë³€í™˜ ê²°ê³¼", converted_text, height=300)
                    st.download_button("ğŸ“¥ ë³€í™˜ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", converted_text, file_name="converted.md")

                if do_review and converted_text:
                    st.subheader("ğŸ“‹ 2ë‹¨ê³„: Markdown ê²€í† ")
                    sections = split_pdf_sections(converted_text)
                    all_results = []
                    total = len(sections)
                    for i, section in enumerate(sections):
                        update_progress(i+1, total, "ê²€í† ")
                        res = review_pdf_section(model, section, i+1)
                        all_results.append(res)
                        time.sleep(2)
                    
                    report = generate_report_for_pdf(all_results)
                    st.text_area("ê²€í†  ë³´ê³ ì„œ", report, height=300)
                    st.download_button("ğŸ“¥ ê²€í†  ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ", report, file_name="report_2512.md")
                    st.success("ì™„ë£Œ!")
            finally:
                if os.path.exists(tmp_path): os.remove(tmp_path)

# ==========================================
# [ì•± ì‹¤í–‰ ì§„ì…ì ]
# ==========================================
if st.session_state.current_page == 'main': main_page()
elif st.session_state.current_page == '2512': page_2512()
elif st.session_state.current_page == 'dev': page_dev()





